<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.3 Collider bias | Notes for Statistical Rethinking 2nd ed. by Richard McElreath" />
<meta property="og:type" content="book" />






<meta name="date" content="2021-12-04" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="6.3 Collider bias | Notes for Statistical Rethinking 2nd ed. by Richard McElreath">

<title>6.3 Collider bias | Notes for Statistical Rethinking 2nd ed. by Richard McElreath</title>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.18/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#index">Index</a></li>
<li><a href="1-the-golem-of-prague.html#the-golem-of-prague"><span class="toc-section-number">1</span> The Golem of Prague</a></li>
<li class="has-sub"><a href="2-small-worlds-and-large-worlds.html#small-worlds-and-large-worlds"><span class="toc-section-number">2</span> Small Worlds and Large Worlds</a>
<ul>
<li><a href="2.1-the-garden-of-forking-data.html#the-garden-of-forking-data"><span class="toc-section-number">2.1</span> The garden of forking data</a></li>
<li><a href="2.2-building-a-model.html#building-a-model"><span class="toc-section-number">2.2</span> Building a model</a></li>
<li><a href="2.3-components-of-the-model.html#components-of-the-model"><span class="toc-section-number">2.3</span> Components of the model</a></li>
<li class="has-sub"><a href="2.4-making-the-model-go.html#making-the-model-go"><span class="toc-section-number">2.4</span> Making the model go</a>
<ul>
<li><a href="2.4-making-the-model-go.html#markov-chain-monte-carlo"><span class="toc-section-number">2.4.1</span> Markov chain Monte Carlo</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="3-sampling-from-the-imaginary.html#sampling-from-the-imaginary"><span class="toc-section-number">3</span> Sampling from the Imaginary</a>
<ul>
<li><a href="3.1-sampling-from-a-grid-approximate-posterior.html#sampling-from-a-grid-approximate-posterior"><span class="toc-section-number">3.1</span> Sampling from a grid-approximate posterior</a></li>
<li><a href="3.2-sampling-to-summarize.html#sampling-to-summarize"><span class="toc-section-number">3.2</span> Sampling to summarize</a></li>
<li><a href="3.3-sampling-to-simulate-prediction.html#sampling-to-simulate-prediction"><span class="toc-section-number">3.3</span> Sampling to simulate prediction</a></li>
<li><a href="3.4-lets-practice-with-brms.html#lets-practice-with-brms"><span class="toc-section-number">3.4</span> Let’s practice with brms</a></li>
<li><a href="practice.html#practice">Practice</a></li>
<li><a href="homework-week-1.html#homework-week-1">Homework: week 1</a></li>
</ul></li>
<li class="has-sub"><a href="4-geocentric-models.html#geocentric-models"><span class="toc-section-number">4</span> Geocentric Models</a>
<ul>
<li><a href="4.1-why-normal-distributions-are-normal.html#why-normal-distributions-are-normal"><span class="toc-section-number">4.1</span> Why normal distributions are normal</a></li>
<li><a href="4.2-a-language-for-describing-models.html#a-language-for-describing-models"><span class="toc-section-number">4.2</span> A language for describing models</a></li>
<li><a href="4.3-gaussian-model-of-height.html#gaussian-model-of-height"><span class="toc-section-number">4.3</span> Gaussian model of height</a></li>
<li><a href="4.4-linear-prediction.html#linear-prediction"><span class="toc-section-number">4.4</span> Linear prediction</a></li>
<li><a href="4.5-curves-from-lines.html#curves-from-lines"><span class="toc-section-number">4.5</span> Curves from lines</a></li>
<li><a href="4.6-practice-1.html#practice-1"><span class="toc-section-number">4.6</span> Practice</a></li>
</ul></li>
<li class="has-sub"><a href="5-the-many-variables-the-spurious-waffles.html#the-many-variables-the-spurious-waffles"><span class="toc-section-number">5</span> The Many Variables &amp; The Spurious Waffles</a>
<ul>
<li><a href="5.1-spurious-association.html#spurious-association"><span class="toc-section-number">5.1</span> Spurious association</a></li>
<li><a href="5.2-masked-relationship.html#masked-relationship"><span class="toc-section-number">5.2</span> Masked relationship</a></li>
<li><a href="5.3-categorical-variables.html#categorical-variables"><span class="toc-section-number">5.3</span> Categorical variables</a></li>
<li><a href="5.4-practice-2.html#practice-2"><span class="toc-section-number">5.4</span> Practice</a></li>
</ul></li>
<li class="has-sub"><a href="6-the-haunted-dag-the-causal-terror.html#the-haunted-dag-the-causal-terror"><span class="toc-section-number">6</span> The Haunted DAG &amp; The Causal Terror</a>
<ul>
<li><a href="6.1-multicollinearity.html#multicollinearity"><span class="toc-section-number">6.1</span> Multicollinearity</a></li>
<li><a href="6.2-post-treatment-bias.html#post-treatment-bias"><span class="toc-section-number">6.2</span> Post-treatment bias</a></li>
<li><a href="6.3-collider-bias.html#collider-bias"><span class="toc-section-number">6.3</span> Collider bias</a></li>
<li><a href="6.4-confronting-confounding.html#confronting-confounding"><span class="toc-section-number">6.4</span> Confronting confounding</a></li>
<li><a href="6.5-summary.html#summary"><span class="toc-section-number">6.5</span> Summary</a></li>
<li><a href="6.6-practice-3.html#practice-3"><span class="toc-section-number">6.6</span> Practice</a></li>
</ul></li>
<li class="has-sub"><a href="7-ulysses-compass.html#ulysses-compass"><span class="toc-section-number">7</span> Ulysses’ Compass</a>
<ul>
<li><a href="7.1-the-problem-with-parameters.html#the-problem-with-parameters"><span class="toc-section-number">7.1</span> The problem with parameters</a></li>
<li><a href="7.2-entropy-and-accuracy.html#entropy-and-accuracy"><span class="toc-section-number">7.2</span> Entropy and accuracy</a></li>
<li><a href="7.3-golem-taming-regularization.html#golem-taming-regularization"><span class="toc-section-number">7.3</span> Golem taming: regularization</a></li>
<li><a href="7.4-predicting-predictive-accuracy.html#predicting-predictive-accuracy"><span class="toc-section-number">7.4</span> Predicting predictive accuracy</a></li>
<li><a href="7.5-model-comparison.html#model-comparison"><span class="toc-section-number">7.5</span> Model comparison</a></li>
<li><a href="7.6-practice-4.html#practice-4"><span class="toc-section-number">7.6</span> Practice</a></li>
</ul></li>
<li class="has-sub"><a href="8-conditional-manatees.html#conditional-manatees"><span class="toc-section-number">8</span> Conditional Manatees</a>
<ul>
<li><a href="8.1-building-an-interaction.html#building-an-interaction"><span class="toc-section-number">8.1</span> Building an interaction</a></li>
<li><a href="8.2-symmetry-of-interactions.html#symmetry-of-interactions"><span class="toc-section-number">8.2</span> Symmetry of interactions</a></li>
<li><a href="8.3-continuous-interactions.html#continuous-interactions"><span class="toc-section-number">8.3</span> Continuous interactions</a></li>
</ul></li>
<li class="has-sub"><a href="9-markov-chain-monte-carlo-1.html#markov-chain-monte-carlo-1"><span class="toc-section-number">9</span> Markov Chain Monte Carlo</a>
<ul>
<li><a href="9.1-good-king-markov-and-his-island-kingdom.html#good-king-markov-and-his-island-kingdom"><span class="toc-section-number">9.1</span> Good King Markov and his island kingdom</a></li>
<li><a href="9.2-metropolis-algorithm.html#metropolis-algorithm"><span class="toc-section-number">9.2</span> Metropolis algorithm</a></li>
<li><a href="9.3-hamiltonian-monte-carlo.html#hamiltonian-monte-carlo"><span class="toc-section-number">9.3</span> Hamiltonian Monte Carlo</a></li>
<li><a href="9.4-easy-hmc-ulam.html#easy-hmc-ulam"><span class="toc-section-number">9.4</span> Easy HMC: <code>ulam</code></a></li>
<li><a href="9.5-care-and-feeding-of-your-markov-chain.html#care-and-feeding-of-your-markov-chain"><span class="toc-section-number">9.5</span> Care and feeding of your Markov chain</a></li>
</ul></li>
<li class="has-sub"><a href="10-big-entropy-and-the-generalized-linear-model.html#big-entropy-and-the-generalized-linear-model"><span class="toc-section-number">10</span> Big Entropy and the Generalized Linear Model</a>
<ul>
<li><a href="10.1-maximum-entropy.html#maximum-entropy"><span class="toc-section-number">10.1</span> Maximum entropy</a></li>
<li><a href="10.2-generalized-linear-models.html#generalized-linear-models"><span class="toc-section-number">10.2</span> Generalized linear models</a></li>
</ul></li>
<li class="has-sub"><a href="11-god-spiked-the-integers.html#god-spiked-the-integers"><span class="toc-section-number">11</span> God Spiked the Integers</a>
<ul>
<li><a href="11.1-binomial-regression.html#binomial-regression"><span class="toc-section-number">11.1</span> Binomial regression</a></li>
<li><a href="11.2-poisson-regression.html#poisson-regression"><span class="toc-section-number">11.2</span> Poisson regression</a></li>
<li><a href="11.3-multinomial-and-categorical-models.html#multinomial-and-categorical-models"><span class="toc-section-number">11.3</span> Multinomial and categorical models</a></li>
</ul></li>
<li class="has-sub"><a href="12-models-with-memory.html#models-with-memory"><span class="toc-section-number">12</span> Models With Memory</a>
<ul>
<li><a href="12.1-example-multilevel-tadpoles.html#example-multilevel-tadpoles"><span class="toc-section-number">12.1</span> Example: Multilevel tadpoles</a></li>
<li><a href="12.2-varying-effects-and-the-underfittingoverfitting-trade-off.html#varying-effects-and-the-underfittingoverfitting-trade-off"><span class="toc-section-number">12.2</span> Varying effects and the underfitting/overfitting trade-off</a></li>
<li><a href="12.3-more-than-one-type-of-cluster.html#more-than-one-type-of-cluster"><span class="toc-section-number">12.3</span> More than one type of cluster</a></li>
<li><a href="12.4-divergent-transitions-and-non-centered-priors.html#divergent-transitions-and-non-centered-priors"><span class="toc-section-number">12.4</span> Divergent transitions and non-centered priors</a></li>
<li><a href="12.5-multilevel-posterior-predictions.html#multilevel-posterior-predictions"><span class="toc-section-number">12.5</span> Multilevel posterior predictions</a></li>
</ul></li>
<li class="has-sub"><a href="13-adventures-in-covariance.html#adventures-in-covariance"><span class="toc-section-number">13</span> Adventures in Covariance</a>
<ul>
<li><a href="13.1-varying-slopes-by-construction.html#varying-slopes-by-construction"><span class="toc-section-number">13.1</span> Varying slopes by construction</a></li>
<li><a href="13.2-advanced-varying-slopes.html#advanced-varying-slopes"><span class="toc-section-number">13.2</span> Advanced varying slopes</a></li>
<li><a href="13.3-instruments-and-causal-designs.html#instruments-and-causal-designs"><span class="toc-section-number">13.3</span> Instruments and causal designs</a></li>
<li><a href="13.4-social-relations-as-correlated-varying-effects.html#social-relations-as-correlated-varying-effects"><span class="toc-section-number">13.4</span> Social relations as correlated varying effects</a></li>
<li><a href="13.5-continuous-categories-and-the-gaussian-process.html#continuous-categories-and-the-gaussian-process"><span class="toc-section-number">13.5</span> Continuous categories and the Gaussian process</a></li>
<li><a href="13.6-bonus-multilevel-growth-models-and-the-melsm.html#bonus-multilevel-growth-models-and-the-melsm"><span class="toc-section-number">13.6</span> Bonus: Multilevel growth models and the MELSM</a></li>
</ul></li>
<li class="has-sub"><a href="14-missing-data-and-other-opportunities.html#missing-data-and-other-opportunities"><span class="toc-section-number">14</span> Missing Data and Other Opportunities</a>
<ul>
<li><a href="14.1-measurement-error.html#measurement-error"><span class="toc-section-number">14.1</span> Measurement error</a></li>
<li><a href="14.2-missing-data.html#missing-data"><span class="toc-section-number">14.2</span> Missing data</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="collider-bias" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Collider bias</h2>
<div class="figure">
<img src="slides/L06/16.png" alt="This is where the selection effect comes from. Like the fork but in reverse. Here `Z` is a common result of `X` and `Y`. X and Y are really independent, but if you condition on Z, it creates a spurious causal connection between X and Y. There's this &quot;finding out&quot; effect. " width="80%" />
<p class="caption marginnote shownote">
This is where the selection effect comes from. Like the fork but in reverse. Here <code>Z</code> is a common result of <code>X</code> and <code>Y</code>. X and Y are really independent, but if you condition on Z, it creates a spurious causal connection between X and Y. There’s this “finding out” effect.
</p>
</div>
<p><img src="slides/L06/17.png" width="80%" /></p>
<div class="figure">
<img src="slides/L06/18.png" alt="This is the finding out effect. Works for continuous variables as well. " width="80%" />
<p class="caption marginnote shownote">
This is the finding out effect. Works for continuous variables as well.
</p>
</div>
<p><img src="slides/L06/19.png" width="80%" /></p>
<div class="figure">
<img src="slides/L06/20.png" alt="Both influence publication." width="80%" />
<p class="caption marginnote shownote">
Both influence publication.
</p>
</div>
<div class="figure">
<img src="slides/L06/21.png" alt="So if it's been published in Nature and isn't trustworthy, can you tell me how newsworthy it is?" width="80%" />
<p class="caption marginnote shownote">
So if it’s been published in Nature and isn’t trustworthy, can you tell me how newsworthy it is?
</p>
</div>
<div class="figure">
<img src="slides/L06/22.png" alt="There are lots of effects like this that happen all the time. Being tall is definitely causatively-speaking an advantage. The taller you are, the easier to score field goals. But conditional on being a professional player, there's no correlation between height and shooting percentage. Because the shorter players are compensating by being amazing in other ways. They've been distorted by the selection effects." width="80%" />
<p class="caption marginnote shownote">
There are lots of effects like this that happen all the time. Being tall is definitely causatively-speaking an advantage. The taller you are, the easier to score field goals. But conditional on being a professional player, there’s no correlation between height and shooting percentage. Because the shorter players are compensating by being amazing in other ways. They’ve been distorted by the selection effects.
</p>
</div>
<p><strong><em>6.3.1. Collider of false sorrow</em></strong></p>
<div class="figure">
<img src="slides/L06/23.png" alt="Let's do an example. Image this causal graph at the bottom. Imagine it's true that getting married is positively, causally associated with happiness, and age. Now our question is, is there any causal impact of age on happiness? Here's a simulation where it's totally spurious. " width="80%" />
<p class="caption marginnote shownote">
Let’s do an example. Image this causal graph at the bottom. Imagine it’s true that getting married is positively, causally associated with happiness, and age. Now our question is, is there any causal impact of age on happiness? Here’s a simulation where it’s totally spurious.
</p>
</div>
<div class="figure">
<img src="slides/L06/24.png" alt="Here the simulation is slightly different to the usual `rnorm`. Here's the algorithm. Uniform happiness at birth. Distributed from 0 to 1. Reality is more complicated, even harder to figure out. At 18 years old, you're eligible to marry. Then you have your coin-flip chance to get married. The chance is proportional to your happiness, which is constant. Age itself doesn't cause marriage, but each year you're alive you have another chance to get married. Married people remain married unto death. Then everyone moves to Spain. 1300 people, 3 variables, over 1000 years." width="80%" />
<p class="caption marginnote shownote">
Here the simulation is slightly different to the usual <code>rnorm</code>. Here’s the algorithm. Uniform happiness at birth. Distributed from 0 to 1. Reality is more complicated, even harder to figure out. At 18 years old, you’re eligible to marry. Then you have your coin-flip chance to get married. The chance is proportional to your happiness, which is constant. Age itself doesn’t cause marriage, but each year you’re alive you have another chance to get married. Married people remain married unto death. Then everyone moves to Spain. 1300 people, 3 variables, over 1000 years.
</p>
</div>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="6.3-collider-bias.html#cb453-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">sim_happiness</span>(<span class="at">seed =</span> <span class="dv">1977</span>, <span class="at">N_years =</span> <span class="dv">1000</span>)</span>
<span id="cb453-2"><a href="6.3-collider-bias.html#cb453-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb453-3"><a href="6.3-collider-bias.html#cb453-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(d)</span></code></pre></div>
<pre><code>##   age married  happiness
## 1  65       0 -2.0000000
## 2  65       0 -1.7894737
## 3  65       1 -1.5789474
## 4  65       0 -1.3684211
## 5  65       0 -1.1578947
## 6  65       0 -0.9473684</code></pre>
<p>Summarise the variables:</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="6.3-collider-bias.html#cb455-1" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> </span>
<span id="cb455-2"><a href="6.3-collider-bias.html#cb455-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb455-3"><a href="6.3-collider-bias.html#cb455-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(name) <span class="sc">%&gt;%</span> </span>
<span id="cb455-4"><a href="6.3-collider-bias.html#cb455-4" aria-hidden="true" tabindex="-1"></a>  tidybayes<span class="sc">::</span><span class="fu">mean_qi</span>(value) <span class="sc">%&gt;%</span> </span>
<span id="cb455-5"><a href="6.3-collider-bias.html#cb455-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.double, round, <span class="at">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 7
##   name      value .lower .upper .width .point .interval
##   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 age        33        2     64   0.95 mean   qi       
## 2 happiness   0       -2      2   0.95 mean   qi       
## 3 married     0.3      0      1   0.95 mean   qi</code></pre>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="6.3-collider-bias.html#cb457-1" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> </span>
<span id="cb457-2"><a href="6.3-collider-bias.html#cb457-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">married =</span> <span class="fu">factor</span>(married,</span>
<span id="cb457-3"><a href="6.3-collider-bias.html#cb457-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;unmarried&quot;</span>, <span class="st">&quot;married&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb457-4"><a href="6.3-collider-bias.html#cb457-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb457-5"><a href="6.3-collider-bias.html#cb457-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> happiness, <span class="at">color =</span> married)) <span class="sc">+</span></span>
<span id="cb457-6"><a href="6.3-collider-bias.html#cb457-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.75</span>) <span class="sc">+</span></span>
<span id="cb457-7"><a href="6.3-collider-bias.html#cb457-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="cn">NULL</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;grey85&quot;</span>, <span class="st">&quot;forestgreen&quot;</span>)) <span class="sc">+</span></span>
<span id="cb457-8"><a href="6.3-collider-bias.html#cb457-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(.<span class="dv">015</span>, .<span class="dv">015</span>)) <span class="sc">+</span></span>
<span id="cb457-9"><a href="6.3-collider-bias.html#cb457-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<div class="figure">
<img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/unnamed-chunk-46-1.png" alt="Figure 6.5" width="672" />
<p class="caption marginnote shownote">
Figure 6.5
</p>
</div>
<p>Rescale age so that the range from 18 to 65 is one unit, i.e. <code>A</code> ranges from 0 to 1, where 0 is age 18 and 1 is age 65:</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="6.3-collider-bias.html#cb458-1" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span></span>
<span id="cb458-2"><a href="6.3-collider-bias.html#cb458-2" aria-hidden="true" tabindex="-1"></a>  d <span class="sc">%&gt;%</span> </span>
<span id="cb458-3"><a href="6.3-collider-bias.html#cb458-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&gt;</span> <span class="dv">17</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb458-4"><a href="6.3-collider-bias.html#cb458-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">a =</span> (age <span class="sc">-</span> <span class="dv">18</span>) <span class="sc">/</span> (<span class="dv">65</span> <span class="sc">-</span> <span class="dv">18</span>))</span>
<span id="cb458-5"><a href="6.3-collider-bias.html#cb458-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb458-6"><a href="6.3-collider-bias.html#cb458-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(d2)</span></code></pre></div>
<pre><code>##   age married  happiness a
## 1  65       0 -2.0000000 1
## 2  65       0 -1.7894737 1
## 3  65       1 -1.5789474 1
## 4  65       0 -1.3684211 1
## 5  65       0 -1.1578947 1
## 6  65       0 -0.9473684 1</code></pre>
<p>Save <code>mid</code> as a factor to make the results easier to interpret:</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="6.3-collider-bias.html#cb460-1" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span></span>
<span id="cb460-2"><a href="6.3-collider-bias.html#cb460-2" aria-hidden="true" tabindex="-1"></a>  d2 <span class="sc">%&gt;%</span> </span>
<span id="cb460-3"><a href="6.3-collider-bias.html#cb460-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mid =</span> <span class="fu">factor</span>(married <span class="sc">+</span> <span class="dv">1</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;single&quot;</span>, <span class="st">&quot;married&quot;</span>)))</span>
<span id="cb460-4"><a href="6.3-collider-bias.html#cb460-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb460-5"><a href="6.3-collider-bias.html#cb460-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(d2)</span></code></pre></div>
<pre><code>##   age married  happiness a     mid
## 1  65       0 -2.0000000 1  single
## 2  65       0 -1.7894737 1  single
## 3  65       1 -1.5789474 1 married
## 4  65       0 -1.3684211 1  single
## 5  65       0 -1.1578947 1  single
## 6  65       0 -0.9473684 1  single</code></pre>
<p>Approximate the posterior</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="6.3-collider-bias.html#cb462-1" aria-hidden="true" tabindex="-1"></a>b6<span class="fl">.9</span> <span class="ot">&lt;-</span> </span>
<span id="cb462-2"><a href="6.3-collider-bias.html#cb462-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> d2, </span>
<span id="cb462-3"><a href="6.3-collider-bias.html#cb462-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> gaussian,</span>
<span id="cb462-4"><a href="6.3-collider-bias.html#cb462-4" aria-hidden="true" tabindex="-1"></a>      happiness <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> mid <span class="sc">+</span> a,</span>
<span id="cb462-5"><a href="6.3-collider-bias.html#cb462-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b, <span class="at">coef =</span> midmarried),</span>
<span id="cb462-6"><a href="6.3-collider-bias.html#cb462-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b, <span class="at">coef =</span> midsingle),</span>
<span id="cb462-7"><a href="6.3-collider-bias.html#cb462-7" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="at">class =</span> b, <span class="at">coef =</span> a),</span>
<span id="cb462-8"><a href="6.3-collider-bias.html#cb462-8" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)),</span>
<span id="cb462-9"><a href="6.3-collider-bias.html#cb462-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb462-10"><a href="6.3-collider-bias.html#cb462-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">6</span>,</span>
<span id="cb462-11"><a href="6.3-collider-bias.html#cb462-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">file =</span> <span class="st">&quot;fits/b06.09&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="6.3-collider-bias.html#cb463-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b6<span class="fl">.9</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: happiness ~ 0 + mid + a 
##    Data: d2 (Number of observations: 960) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## midsingle     -0.23      0.06    -0.36    -0.11 1.00     1649     2365
## midmarried     1.26      0.09     1.09     1.43 1.00     1665     2341
## a             -0.75      0.11    -0.97    -0.53 1.00     1501     1925
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.99      0.02     0.95     1.04 1.00     2380     2263
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The model is quite sure that age is negatively associated with happiness. We’d like to compare the inferences from this model to a model that omits marriage status:</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="6.3-collider-bias.html#cb465-1" aria-hidden="true" tabindex="-1"></a>b6<span class="fl">.10</span> <span class="ot">&lt;-</span> </span>
<span id="cb465-2"><a href="6.3-collider-bias.html#cb465-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> d2, </span>
<span id="cb465-3"><a href="6.3-collider-bias.html#cb465-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> gaussian,</span>
<span id="cb465-4"><a href="6.3-collider-bias.html#cb465-4" aria-hidden="true" tabindex="-1"></a>      happiness <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Intercept <span class="sc">+</span> a,</span>
<span id="cb465-5"><a href="6.3-collider-bias.html#cb465-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b, <span class="at">coef =</span> Intercept),</span>
<span id="cb465-6"><a href="6.3-collider-bias.html#cb465-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="at">class =</span> b, <span class="at">coef =</span> a),</span>
<span id="cb465-7"><a href="6.3-collider-bias.html#cb465-7" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)),</span>
<span id="cb465-8"><a href="6.3-collider-bias.html#cb465-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb465-9"><a href="6.3-collider-bias.html#cb465-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">6</span>,</span>
<span id="cb465-10"><a href="6.3-collider-bias.html#cb465-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">file =</span> <span class="st">&quot;fits/b06.10&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="6.3-collider-bias.html#cb466-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b6<span class="fl">.10</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: happiness ~ 0 + Intercept + a 
##    Data: d2 (Number of observations: 960) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.00      0.08    -0.15     0.15 1.00     1514     1752
## a             0.00      0.13    -0.25     0.25 1.00     1626     2112
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.22      0.03     1.17     1.27 1.00     2363     1956
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<blockquote>
<p>The collider is marriage status. It is a common consequence of age and happiness.</p>
</blockquote>
<div class="figure">
<img src="slides/L06/25.png" alt="Here's the system. Run a regression where we take happiness. Happiness is the outcome, then the linear model `mu`, the slope `a` which is age. That's the exposure we're interested in. And we know the marriage status, so perhaps we control for that. (No, that's the wrong thing to do, as we'll see.) Created an index variable. Then put that in as a control. We see that single people are less happy. Regression models don't have arrows. It's not in the Bayesian network; that's what the DAG does. `a[2]` is married individuals. Positive `mu`. The slope is solidly negative. But this is a spurious correlation by conditioning on a collider. " width="80%" />
<p class="caption marginnote shownote">
Here’s the system. Run a regression where we take happiness. Happiness is the outcome, then the linear model <code>mu</code>, the slope <code>a</code> which is age. That’s the exposure we’re interested in. And we know the marriage status, so perhaps we control for that. (No, that’s the wrong thing to do, as we’ll see.) Created an index variable. Then put that in as a control. We see that single people are less happy. Regression models don’t have arrows. It’s not in the Bayesian network; that’s what the DAG does. <code>a[2]</code> is married individuals. Positive <code>mu</code>. The slope is solidly negative. But this is a spurious correlation by conditioning on a collider.
</p>
</div>
<div class="figure">
<img src="slides/L06/26.png" alt="We know that happiness doesn't change and doesn't decline with age, because that's how we coded it. But if we stratify by marriage status, it does. Each point is a person. Each year 20 individuals are born. Happiness is uniformly distributed and constant. Blue filled are married. Starting early on the blue points are only at the top. But over time, indiviuals who are less happy will also get married. By 65, most of the population in the simulation is married." width="80%" />
<p class="caption marginnote shownote">
We know that happiness doesn’t change and doesn’t decline with age, because that’s how we coded it. But if we stratify by marriage status, it does. Each point is a person. Each year 20 individuals are born. Happiness is uniformly distributed and constant. Blue filled are married. Starting early on the blue points are only at the top. But over time, indiviuals who are less happy will also get married. By 65, most of the population in the simulation is married.
</p>
</div>
<div class="figure">
<img src="slides/L06/27.png" alt="Now if we draw regression lines, we can see there's a negative correlation. But the distribution of happiness has not changed for anybody." width="80%" />
<p class="caption marginnote shownote">
Now if we draw regression lines, we can see there’s a negative correlation. But the distribution of happiness has not changed for anybody.
</p>
</div>
<div class="figure">
<img src="slides/L06/28.png" alt="If we condition on it, we allow information to flow from age to happiness. In reality we don't know, so we need to use information external to the data. " width="80%" />
<p class="caption marginnote shownote">
If we condition on it, we allow information to flow from age to happiness. In reality we don’t know, so we need to use information external to the data.
</p>
</div>
<p><strong><em>6.3.2. The haunted DAG</em></strong></p>
<div class="figure">
<img src="slides/L06/29.png" alt="Another example. Colliders are so powerful they can even occur when you haven't measured the confounder. In my subfield, we're interested in allopaternal effects. What is the material benefit of having grandparents? There are resource and information flows, so we want to figure out how important they are. How do you figure this out empirically? Say you have triads, and you're looking at educational outcomes. Indirect path through P, say through books. But also a potential direct effects during say babysitting. But regressions can show that grandparents have a negative effect?" width="80%" />
<p class="caption marginnote shownote">
Another example. Colliders are so powerful they can even occur when you haven’t measured the confounder. In my subfield, we’re interested in allopaternal effects. What is the material benefit of having grandparents? There are resource and information flows, so we want to figure out how important they are. How do you figure this out empirically? Say you have triads, and you’re looking at educational outcomes. Indirect path through P, say through books. But also a potential direct effects during say babysitting. But regressions can show that grandparents have a negative effect?
</p>
</div>
<div class="figure">
<img src="slides/L06/30.png" alt="It's plausible that parents and children share unobserved confounds. Whenever you do observational studies, there are `U`s all over the place. e.g. the neighbourhood you live in. School and neighbourhood effects are really powerful. Makes parents into a collider. So if we condition on parents, it becomes a collider. " width="80%" />
<p class="caption marginnote shownote">
It’s plausible that parents and children share unobserved confounds. Whenever you do observational studies, there are <code>U</code>s all over the place. e.g. the neighbourhood you live in. School and neighbourhood effects are really powerful. Makes parents into a collider. So if we condition on parents, it becomes a collider.
</p>
</div>
<div class="figure">
<img src="slides/L06/31.png" alt="So we simulate this. Assuming that the direct path is 0." width="80%" />
<p class="caption marginnote shownote">
So we simulate this. Assuming that the direct path is 0.
</p>
</div>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="6.3-collider-bias.html#cb468-1" aria-hidden="true" tabindex="-1"></a><span class="co"># how many grandparent-parent-child triads would you like?</span></span>
<span id="cb468-2"><a href="6.3-collider-bias.html#cb468-2" aria-hidden="true" tabindex="-1"></a>n    <span class="ot">&lt;-</span> <span class="dv">200</span> </span>
<span id="cb468-3"><a href="6.3-collider-bias.html#cb468-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb468-4"><a href="6.3-collider-bias.html#cb468-4" aria-hidden="true" tabindex="-1"></a>b_gp <span class="ot">&lt;-</span> <span class="dv">1</span>  <span class="co"># direct effect of G on P</span></span>
<span id="cb468-5"><a href="6.3-collider-bias.html#cb468-5" aria-hidden="true" tabindex="-1"></a>b_gc <span class="ot">&lt;-</span> <span class="dv">0</span>  <span class="co"># direct effect of G on C</span></span>
<span id="cb468-6"><a href="6.3-collider-bias.html#cb468-6" aria-hidden="true" tabindex="-1"></a>b_pc <span class="ot">&lt;-</span> <span class="dv">1</span>  <span class="co"># direct effect of P on C</span></span>
<span id="cb468-7"><a href="6.3-collider-bias.html#cb468-7" aria-hidden="true" tabindex="-1"></a>b_u  <span class="ot">&lt;-</span> <span class="dv">2</span>  <span class="co"># direct effect of U on P and C</span></span>
<span id="cb468-8"><a href="6.3-collider-bias.html#cb468-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb468-9"><a href="6.3-collider-bias.html#cb468-9" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate triads</span></span>
<span id="cb468-10"><a href="6.3-collider-bias.html#cb468-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb468-11"><a href="6.3-collider-bias.html#cb468-11" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span></span>
<span id="cb468-12"><a href="6.3-collider-bias.html#cb468-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">u =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">rbinom</span>(n, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> .<span class="dv">5</span>) <span class="sc">-</span> <span class="dv">1</span>,</span>
<span id="cb468-13"><a href="6.3-collider-bias.html#cb468-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">g =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb468-14"><a href="6.3-collider-bias.html#cb468-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> b_gp <span class="sc">*</span> g <span class="sc">+</span> b_u <span class="sc">*</span> u, <span class="at">sd =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb468-15"><a href="6.3-collider-bias.html#cb468-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">c =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> b_pc <span class="sc">*</span> p <span class="sc">+</span> b_gc <span class="sc">*</span> g <span class="sc">+</span> b_u <span class="sc">*</span> u, <span class="at">sd =</span> <span class="dv">1</span>))</span>
<span id="cb468-16"><a href="6.3-collider-bias.html#cb468-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb468-17"><a href="6.3-collider-bias.html#cb468-17" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(d)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 4
##       u       g     p     c
##   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    -1 -0.620  -1.73 -3.65
## 2    -1  0.0421 -3.01 -5.30
## 3     1 -0.911   3.06  3.88
## 4     1  0.158   1.77  3.79
## 5    -1 -0.655  -1.00 -2.01
## 6     1  1.77    5.28  8.87</code></pre>
<div class="figure">
<img src="slides/L06/32.png" alt="We end up concluding that grandparents hurt their kids. How does this work? Conditioning on a collider opens a path. It's closed by default. This oepns a path from G through U to see, which creates a spurious correlation." width="80%" />
<p class="caption marginnote shownote">
We end up concluding that grandparents hurt their kids. How does this work? Conditioning on a collider opens a path. It’s closed by default. This oepns a path from G through U to see, which creates a spurious correlation.
</p>
</div>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="6.3-collider-bias.html#cb470-1" aria-hidden="true" tabindex="-1"></a>b6<span class="fl">.11</span> <span class="ot">&lt;-</span> </span>
<span id="cb470-2"><a href="6.3-collider-bias.html#cb470-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> d, </span>
<span id="cb470-3"><a href="6.3-collider-bias.html#cb470-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> gaussian,</span>
<span id="cb470-4"><a href="6.3-collider-bias.html#cb470-4" aria-hidden="true" tabindex="-1"></a>      c <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Intercept <span class="sc">+</span> p <span class="sc">+</span> g,</span>
<span id="cb470-5"><a href="6.3-collider-bias.html#cb470-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b),</span>
<span id="cb470-6"><a href="6.3-collider-bias.html#cb470-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)),</span>
<span id="cb470-7"><a href="6.3-collider-bias.html#cb470-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb470-8"><a href="6.3-collider-bias.html#cb470-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">6</span>,</span>
<span id="cb470-9"><a href="6.3-collider-bias.html#cb470-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">file =</span> <span class="st">&quot;fits/b06.11&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="6.3-collider-bias.html#cb471-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b6<span class="fl">.11</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: c ~ 0 + Intercept + p + g 
##    Data: d (Number of observations: 200) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.12      0.10    -0.31     0.07 1.00     3832     3110
## p             1.79      0.04     1.70     1.87 1.00     3508     2925
## g            -0.84      0.11    -1.05    -0.63 1.00     3431     3045
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.43      0.07     1.30     1.58 1.00     4158     3115
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="figure">
<img src="slides/L06/33.png" alt="One way to think about this is on the left we have good neighbourhoods in blue. All filled in points are where the parents are in a particular stratum. Why is it negative? Focus only on parents in the narrow range of educational outcomes. Parents in the good neighbourhoods, to be within this range, they must have had less educated grandparents. There are two ways to become a highly-educated parent. Either you are in a good neighbourhood, or you had an educated parent yourself. Each end the P box. " width="80%" />
<p class="caption marginnote shownote">
One way to think about this is on the left we have good neighbourhoods in blue. All filled in points are where the parents are in a particular stratum. Why is it negative? Focus only on parents in the narrow range of educational outcomes. Parents in the good neighbourhoods, to be within this range, they must have had less educated grandparents. There are two ways to become a highly-educated parent. Either you are in a good neighbourhood, or you had an educated parent yourself. Each end the P box.
</p>
</div>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="6.3-collider-bias.html#cb473-1" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> </span>
<span id="cb473-2"><a href="6.3-collider-bias.html#cb473-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">centile =</span> <span class="fu">ifelse</span>(p <span class="sc">&gt;=</span> <span class="fu">quantile</span>(p, <span class="at">prob =</span> .<span class="dv">45</span>) <span class="sc">&amp;</span> p <span class="sc">&lt;=</span> <span class="fu">quantile</span>(p, <span class="at">prob =</span> .<span class="dv">60</span>), <span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>),</span>
<span id="cb473-3"><a href="6.3-collider-bias.html#cb473-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">u =</span> <span class="fu">factor</span>(u)) <span class="sc">%&gt;%</span></span>
<span id="cb473-4"><a href="6.3-collider-bias.html#cb473-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb473-5"><a href="6.3-collider-bias.html#cb473-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> g, <span class="at">y =</span> c)) <span class="sc">+</span></span>
<span id="cb473-6"><a href="6.3-collider-bias.html#cb473-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">shape =</span> centile, <span class="at">color =</span> u),</span>
<span id="cb473-7"><a href="6.3-collider-bias.html#cb473-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="fl">2.5</span>, <span class="at">stroke =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb473-8"><a href="6.3-collider-bias.html#cb473-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">data =</span> . <span class="sc">%&gt;%</span> <span class="fu">filter</span>(centile <span class="sc">==</span> <span class="st">&quot;a&quot;</span>),</span>
<span id="cb473-9"><a href="6.3-collider-bias.html#cb473-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">fullrange =</span> T) <span class="sc">+</span></span>
<span id="cb473-10"><a href="6.3-collider-bias.html#cb473-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_shape_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">19</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb473-11"><a href="6.3-collider-bias.html#cb473-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;lightblue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb473-12"><a href="6.3-collider-bias.html#cb473-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<div class="figure">
<img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/unnamed-chunk-60-1.png" alt="Figure 6.5" width="672" />
<p class="caption marginnote shownote">
Figure 6.5
</p>
</div>
<p>What can we do about this? We have to measure <span class="math inline">\(U\)</span>:</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="6.3-collider-bias.html#cb475-1" aria-hidden="true" tabindex="-1"></a>b6<span class="fl">.12</span> <span class="ot">&lt;-</span> </span>
<span id="cb475-2"><a href="6.3-collider-bias.html#cb475-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> d, </span>
<span id="cb475-3"><a href="6.3-collider-bias.html#cb475-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> gaussian,</span>
<span id="cb475-4"><a href="6.3-collider-bias.html#cb475-4" aria-hidden="true" tabindex="-1"></a>      c <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> Intercept <span class="sc">+</span> p <span class="sc">+</span> g <span class="sc">+</span> u,</span>
<span id="cb475-5"><a href="6.3-collider-bias.html#cb475-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b),</span>
<span id="cb475-6"><a href="6.3-collider-bias.html#cb475-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">1</span>), <span class="at">class =</span> sigma)),</span>
<span id="cb475-7"><a href="6.3-collider-bias.html#cb475-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb475-8"><a href="6.3-collider-bias.html#cb475-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">6</span>,</span>
<span id="cb475-9"><a href="6.3-collider-bias.html#cb475-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">file =</span> <span class="st">&quot;fits/b06.12&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="6.3-collider-bias.html#cb476-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b6<span class="fl">.12</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: c ~ 0 + Intercept + p + g + u 
##    Data: d (Number of observations: 200) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.12      0.07    -0.27     0.02 1.00     2589     2138
## p             1.01      0.07     0.88     1.15 1.00     1415     1980
## g            -0.04      0.10    -0.24     0.16 1.00     1814     2178
## u             1.99      0.15     1.69     2.29 1.00     1395     1949
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.04      0.05     0.94     1.15 1.00     3001     2545
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Now the posterior for <span class="math inline">\(\beta_g\)</span> is hovering around 0, where it belongs.</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="6.3-collider-bias.html#cb478-1" aria-hidden="true" tabindex="-1"></a>b_gc</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>And those are the slopes we simulated with.</p>
</div>
<p style="text-align: center;">
<a href="6.2-post-treatment-bias.html"><button class="btn btn-default">Previous</button></a>
<a href="6.4-confronting-confounding.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
