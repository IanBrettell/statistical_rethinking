<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2021-04-24" />

<title>Chapter 4. Geocentric Models</title>

<script src="site_libs/header-attrs-2.5/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistical Rethinking</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="01_the_golem_of_prague.html">1. The Golem of Prague</a>
</li>
<li>
  <a href="02_small_worlds_and_large_worlds.html">2. Small Worlds and Large Worlds</a>
</li>
<li>
  <a href="03_sampling_from_the_imaginary.html">3. Sampling from the Imaginary</a>
</li>
<li>
  <a href="04_geocentric_models.html">4. Geocentric models</a>
</li>
<li>
  <a href="11_god_spiked_the_integers.html">11. God spiked the integers</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Chapter 4. Geocentric Models</h1>
<h4 class="date">2021-04-24</h4>

</div>


<div id="setup" class="section level1">
<h1>Setup</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(here)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;code/scripts/source.R&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>slides_dir <span class="ot">=</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;docs/slides/L03&quot;</span>)</span></code></pre></div>
</div>
<div id="text" class="section level1">
<h1>Text</h1>
<p><img src="slides/L03/01.png" width="60%" /></p>
<p>Introduction into regression models.</p>
<p><img src="slides/L03/02.png" width="60%" /></p>
<p>As scientists, we’re always dealing with questions that have higher dimensions and more complexity than what we can measure. Above is the path of Mars, called <em>retrograde motion</em>. It’s an illusion caused by the joint movement of ourselves and Mars. The relative velocities create the illusion.</p>
<p><img src="slides/L03/03.png" width="60%" /></p>
<p>A lot of people published models, but this one is very accurate. They’re full-blown mathematical models. But they’re also wrong. You can’t use them to send a probe to Mars. This is like a regression model. They’re incredibly accurate for specific purposes, but they’re also deeply wrong. Keep in mind the small world / large world distinction.</p>
<p>You could say scientists are geocentric people. The reason Ptolemy’s model works so well is that they used Fourier series - circles in circles (“epicircles”). You can use this for anything with periodic cycles. And this model still works.</p>
<p><img src="slides/L03/04.png" width="60%" /></p>
<p>We’re here to build models of many diverse things. We don’t usually use Fourier models; instead we tend to use regression. Linear regression models are incredibly useful. But if you use them without wisdom, all they do is describe things without wisdom.</p>
<p><img src="slides/L03/05.png" width="60%" /></p>
<p>Statistical golems which measure how the mean of some measure changes when you learn other things. The mean is always modeled as some additive weighted measure of variables.</p>
<p><img src="slides/L03/06.png" width="60%" /></p>
<p>Gauss developed regression, but he did it using a Bayesian argument. He used it to predict when a comet would return.</p>
<div id="why-normal-distributions-are-normal" class="section level2">
<h2>4.1. Why normal distributions are normal</h2>
<p><img src="slides/L03/07.png" width="60%" /></p>
<p>These appear all throughout nature. Why are they so normal? They arise from all over the place.</p>
<div id="normal-by-addition" class="section level3">
<h3>4.1.1. Normal by addition</h3>
<p>One of the things that are nice about them is that they are additive. So easy to work with. Second is that they’re very common.</p>
<p><img src="slides/L03/08.png" width="60%" /></p>
<p>Imagine a football pitch. We all line up on the midfield line. Take a coin out of your pocket and flip it. One step left for heads, right for tails. Do it a few hundred times.</p>
<p><img src="slides/L03/09.png" width="60%" /></p>
<p><img src="slides/L03/10.png" width="60%" /></p>
<p><img src="slides/L03/11.png" width="60%" /></p>
<p><img src="slides/L03/12.png" width="60%" /></p>
<p>The frequency distribution will be Gaussian.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>pos <span class="ot">=</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">16</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(pos))</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.1-1.svg" width="672" /></p>
<p><img src="slides/L03/13.png" width="60%" /></p>
<p>This is a simulation of the soccer field experiment. After four flips (steps). Black follows one particular student. A pattern forms in the aggregation. This isn’t very Gaussian yet.</p>
<p><img src="slides/L03/14.png" width="60%" /></p>
<p>After 8 it’s pretty Gaussian. <img src="slides/L03/15.png" width="60%" /></p>
<p>And after 16 it’s very Gaussian. It’ll get wider and wider over time. Why does this happen? Lot’s of mathematical theorems. But the intuition is that each coin flip is a fluctuation. And in the long run, fluctuations tend to cancel. If you get a string of lefts, eventually you’ll get a string of rights, so the average student will end up near the middle. A very large number of them exactly cancel each other. There are more paths that will give you 0 than any other path. Then there are a few less that give you +1 or -1. And so forth.</p>
<p><img src="slides/L03/16.png" width="60%" /></p>
<p>That’s why a bunch of natural systems are normally distributed. We don’t need to know anything except that they cancel out. A lot of common statistics follow this kind of process. What you’re left with are particular shapes, called <em>maximum entropy distributions</em>. For the Gaussian, <strong>addition</strong> is our friend.</p>
<p>One of the things about it is that products of deviations are actually addition. So lots of multiplicative interactions also produce Gaussian distributions.</p>
<p>You can measure things on logarithmic scales.</p>
<p><img src="slides/L03/18.png" width="60%" /></p>
<p>This is the ontological perspective on distributions. When fluctuations tend to dampen one another, you end up with a symmetric curve. What neat and also frustrating is that you lose a lot of information about the generative processes. When you see heights are normally distributed, you learn basically nothing about it. This is cool because all that’s preserved from the underlying process is the mean and the variance. What’s terrible is that you can’t figure out the process from the distribution.</p>
<p>All the maximum entropy distributions have the same feature. Power laws arise through lots of processes, and it tells you nothing other than it has high variance.</p>
<p>The other perspective is epistemological. If you’re building a model and you want to be as conservative as possible, you should use the Gaussian distribution. Because any other distribution will be narrower. So it’s a very good assumption to use when you don’t have additional information.</p>
<p>The Gaussian is the one where all you’re willing to say is there’s a mean and a variance, you should use the Gaussian. It assumes the least.</p>
</div>
<div id="normal-by-multiplication" class="section level3">
<h3>4.1.2 Normal by multiplication</h3>
<p>This code just samples 12 random numbers between 1.0 and 1.1, each representing a proportional increase in growth. Thus 1.0 means no additional growth and 1.1 means a 10% increase.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, .<span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] 1.744779</code></pre>
<p>Now what distribution do you think these random products will take? Let’s generate 10,000 of them and see:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>growth <span class="ot">=</span> <span class="fu">replicate</span>(<span class="fl">1e4</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(growth, <span class="at">norm.comp =</span> T)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.3-1.svg" width="672" /> Multiplying small numbers if approximately the same as addition.</p>
<p>The smaller the effect of each locus, the better this additive approximation will be. In this way, small effects that multiply together are approximately additive, and so they also tend to stabilize on Gaussian distributions.</p>
<p>Verify by comparing:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>big <span class="ot">=</span> <span class="fu">replicate</span>(<span class="fl">1e4</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, .<span class="dv">5</span>)))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>small <span class="ot">=</span> <span class="fu">replicate</span>(<span class="fl">1e4</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.01</span>)))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(big, <span class="at">norm.comp =</span> T)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.4-1.svg" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(small, <span class="at">norm.comp =</span> T)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.4-2.svg" width="672" /> ### 4.1.3. Normal by log-multiplication</p>
<p>Large deviates that are multiplied together do not produce Gaussian distributions, but they do tend to produce Gaussian distributions on the log scale. e.g.:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>log.big <span class="ot">=</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">log</span>(<span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, .<span class="dv">5</span>))))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(log.big, <span class="at">norm.comp =</span> T)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.5-1.svg" width="672" /> Adding logs is equivalent to multiplying the original numbers.</p>
</div>
<div id="using-gaussian-distributions" class="section level3">
<h3>4.1.4. Using Gaussian distributions</h3>
<p><strong>Caution</strong>: Many natural (and unnatural) processes have much heavier tails - much higher probabilities of producing extreme events.</p>
</div>
</div>
<div id="a-language-for-describing-models" class="section level2">
<h2>4.2. A language for describing models</h2>
<p><img src="slides/L03/19.png" width="60%" /></p>
<p>All of those things are linear models. Just learn the linear modeling strategies instead of the specific procedures. We’ll build up linear models from the ground up. You can build the model you need.</p>
<div id="re-describing-the-glob-tossing-model" class="section level3">
<h3>4.2.1. Re-describing the glob tossing model</h3>
<p><img src="slides/L03/20.png" width="60%" /></p>
<p>We’re going to write out all the models in the same standard notation. We’re going to write this in our code so that it’s reinforced.</p>
<p><img src="slides/L03/21.png" width="60%" /></p>
<p>Same applies for more complex models. Some of these things you can observe (water tosses), and some you can’t (regression slopes). We need to list these variables and then define them.</p>
<p><img src="slides/L03/22.png" width="60%" /></p>
<p>The motor of these linear regression models. There’s some mean of the normal distribution that is explained by <span class="math inline">\(x\)</span>. But <span class="math inline">\(x\)</span> also has a distribution.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="dv">6</span>; n <span class="ot">=</span> <span class="dv">9</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">=</span> <span class="fu">dbinom</span>(w, n, p_grid) <span class="sc">*</span> <span class="fu">dunif</span>(p_grid, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">=</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> <span class="fu">sample</span>(p_grid, <span class="fl">1e5</span>, <span class="at">prob =</span> posterior, <span class="at">replace =</span> T)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(samples)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.6-1.svg" width="672" /> ## 4.3. Gaussian model of height</p>
<p>Before we add a predictor variable, we want to model the outcome variable as a Gaussian distribution. There are an infinite number of possible Gaussian distributions based on infinite combinations of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. We want our Bayesian machine to consider every possible distribution, and rank them by posterior plausibility.</p>
</div>
<div id="the-data" class="section level3">
<h3>4.3.1. The data</h3>
<p><img src="slides/L03/23.png" width="60%" /></p>
<p>These height data come from Nancy Howell’s data. <code>Howell1</code> is a simplified dataset. We’ll focus just on adult heights at the moment.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> Howell1</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    544 obs. of  4 variables:
##  $ height: num  152 140 137 157 145 ...
##  $ weight: num  47.8 36.5 31.9 53 41.3 ...
##  $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
##  $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">precis</span>(d)</span></code></pre></div>
<pre><code>##               mean         sd      5.5%     94.5%     histogram
## height 138.2635963 27.6024476 81.108550 165.73500 ▁▁▁▁▁▁▁▂▁▇▇▅▁
## weight  35.6106176 14.7191782  9.360721  54.50289 ▁▂▃▂▂▂▂▅▇▇▃▂▁
## age     29.3443934 20.7468882  1.000000  66.13500     ▇▅▅▃▅▂▂▁▁
## male     0.4724265  0.4996986  0.000000   1.00000    ▇▁▁▁▁▁▁▁▁▇</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>height</span></code></pre></div>
<pre><code>##   [1] 151.7650 139.7000 136.5250 156.8450 145.4150 163.8300 149.2250 168.9100 147.9550 165.1000 154.3050
##  [12] 151.1300 144.7800 149.9000 150.4950 163.1950 157.4800 143.9418 121.9200 105.4100  86.3600 161.2900
##  [23] 156.2100 129.5400 109.2200 146.4000 148.5900 147.3200 137.1600 125.7300 114.3000 147.9550 161.9250
##  [34] 146.0500 146.0500 152.7048 142.8750 142.8750 147.9550 160.6550 151.7650 162.8648 171.4500 147.3200
##  [45] 147.9550 144.7800 121.9200 128.9050  97.7900 154.3050 143.5100 146.7000 157.4800 127.0000 110.4900
##  [56]  97.7900 165.7350 152.4000 141.6050 158.8000 155.5750 164.4650 151.7650 161.2900 154.3050 145.4150
##  [67] 145.4150 152.4000 163.8300 144.1450 129.5400 129.5400 153.6700 142.8750 146.0500 167.0050 158.4198
##  [78]  91.4400 165.7350 149.8600 147.9550 137.7950 154.9400 160.9598 161.9250 147.9550 113.6650 159.3850
##  [89] 148.5900 136.5250 158.1150 144.7800 156.8450 179.0700 118.7450 170.1800 146.0500 147.3200 113.0300
## [100] 162.5600 133.9850 152.4000 160.0200 149.8600 142.8750 167.0050 159.3850 154.9400 148.5900 111.1250
## [111] 111.7600 162.5600 152.4000 124.4600 111.7600  86.3600 170.1800 146.0500 159.3850 151.1300 160.6550
## [122] 169.5450 158.7500  74.2950 149.8600 153.0350  96.5200 161.9250 162.5600 149.2250 116.8400 100.0760
## [133] 163.1950 161.9250 145.4150 163.1950 151.1300 150.4950 141.6050 170.8150  91.4400 157.4800 152.4000
## [144] 149.2250 129.5400 147.3200 145.4150 121.9200 113.6650 157.4800 154.3050 120.6500 115.6000 167.0050
## [155] 142.8750 152.4000  96.5200 160.0000 159.3850 149.8600 160.6550 160.6550 149.2250 125.0950 140.9700
## [166] 154.9400 141.6050 160.0200 150.1648 155.5750 103.5050  94.6150 156.2100 153.0350 167.0050 149.8600
## [177] 147.9550 159.3850 161.9250 155.5750 159.3850 146.6850 172.7200 166.3700 141.6050 142.8750 133.3500
## [188] 127.6350 119.3800 151.7650 156.8450 148.5900 157.4800 149.8600 147.9550 102.2350 153.0350 160.6550
## [199] 149.2250 114.3000 100.9650 138.4300  91.4400 162.5600 149.2250 158.7500 149.8600 158.1150 156.2100
## [210] 148.5900 143.5100 154.3050 131.4450 157.4800 157.4800 154.3050 107.9500 168.2750 145.4150 147.9550
## [221] 100.9650 113.0300 149.2250 154.9400 162.5600 156.8450 123.1900 161.0106 144.7800 143.5100 149.2250
## [232] 110.4900 149.8600 165.7350 144.1450 157.4800 154.3050 163.8300 156.2100 153.6700 134.6200 144.1450
## [243] 114.3000 162.5600 146.0500 120.6500 154.9400 144.7800 106.6800 146.6850 152.4000 163.8300 165.7350
## [254] 156.2100 152.4000 140.3350 158.1150 163.1950 151.1300 171.1198 149.8600 163.8300 141.6050  93.9800
## [265] 149.2250 105.4100 146.0500 161.2900 162.5600 145.4150 145.4150 170.8150 127.0000 159.3850 159.4000
## [276] 153.6700 160.0200 150.4950 149.2250 127.0000 142.8750 142.1130 147.3200 162.5600 164.4650 160.0200
## [287] 153.6700 167.0050 151.1300 147.9550 125.3998 111.1250 153.0350 139.0650 152.4000 154.9400 147.9550
## [298] 143.5100 117.9830 144.1450  92.7100 147.9550 155.5750 150.4950 155.5750 154.3050 130.6068 101.6000
## [309] 157.4800 168.9100 150.4950 111.7600 160.0200 167.6400 144.1450 145.4150 160.0200 147.3200 164.4650
## [320] 153.0350 149.2250 160.0200 149.2250  85.0900  84.4550  59.6138  92.7100 111.1250  90.8050 153.6700
## [331]  99.6950  62.4840  81.9150  96.5200  80.0100 150.4950 151.7650 140.6398  88.2650 158.1150 149.2250
## [342] 151.7650 154.9400 123.8250 104.1400 161.2900 148.5900  97.1550  93.3450 160.6550 157.4800 167.0050
## [353] 157.4800  91.4400  60.4520 137.1600 152.4000 152.4000  81.2800 109.2200  71.1200  89.2048  67.3100
## [364]  85.0900  69.8500 161.9250 152.4000  88.9000  90.1700  71.7550  83.8200 159.3850 142.2400 142.2400
## [375] 168.9100 123.1900  74.9300  74.2950  90.8050 160.0200  67.9450 135.8900 158.1150  85.0900  93.3450
## [386] 152.4000 155.5750 154.3050 156.8450 120.0150 114.3000  83.8200 156.2100 137.1600 114.3000  93.9800
## [397] 168.2750 147.9550 139.7000 157.4800  76.2000  66.0400 160.7000 114.3000 146.0500 161.2900  69.8500
## [408] 133.9850  67.9450 150.4950 163.1950 148.5900 148.5900 161.9250 153.6700  68.5800 151.1300 163.8300
## [419] 153.0350 151.7650 132.0800 156.2100 140.3350 158.7500 142.8750  84.4550 151.9428 161.2900 127.9906
## [430] 160.9852 144.7800 132.0800 117.9830 160.0200 154.9400 160.9852 165.9890 157.9880 154.9400  97.9932
## [441]  64.1350 160.6550 147.3200 146.7000 147.3200 172.9994 158.1150 147.3200 124.9934 106.0450 165.9890
## [452] 149.8600  76.2000 161.9250 140.0048  66.6750  62.8650 163.8300 147.9550 160.0200 154.9400 152.4000
## [463]  62.2300 146.0500 151.9936 157.4800  55.8800  60.9600 151.7650 144.7800 118.1100  78.1050 160.6550
## [474] 151.1300 121.9200  92.7100 153.6700 147.3200 139.7000 157.4800  91.4400 154.9400 143.5100  83.1850
## [485] 158.1150 147.3200 123.8250  88.9000 160.0200 137.1600 165.1000 154.9400 111.1250 153.6700 145.4150
## [496] 141.6050 144.7800 163.8300 161.2900 154.9000 161.3000 170.1800 149.8600 123.8250  85.0900 160.6550
## [507] 154.9400 106.0450 126.3650 166.3700 148.2852 124.4600  89.5350 101.6000 151.7650 148.5900 153.6700
## [518]  53.9750 146.6850  56.5150 100.9650 121.9200  81.5848 154.9400 156.2100 132.7150 125.0950 101.6000
## [529] 160.6550 146.0500 132.7150  87.6300 156.2100 152.4000 162.5600 114.9350  67.9450 142.8750  76.8350
## [540] 145.4150 162.5600 156.2100  71.1200 158.7500</code></pre>
<p>Filter for adults:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">=</span> d[d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span>, ]</span></code></pre></div>
</div>
<div id="the-model" class="section level3">
<h3>4.3.2. The model</h3>
<p><img src="slides/L03/24.png" width="60%" /></p>
<p>Here’s the distribution of height data. <span class="math inline">\(h\)</span> is distributed normally. <img src="slides/L03/25.png" width="60%" /></p>
<p>There’s nothing special about the particular letters used. But it’s important to be able to read this. Now we have three variables. One is observed, and two have not. We have to infrer them from <span class="math inline">\(h\)</span>.</p>
<p><img src="slides/L03/26.png" width="60%" /></p>
<p>Because this is Bayesian, they have prior distributions. Using 187 cm (height of Richard) as the prior. Standard deviation is on the mean. 20 is very generous. Then for sigma, uniform 50.</p>
<p>Whatever the prior, it’s a very good idea to plot your priors:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="dv">178</span>, <span class="dv">20</span>), <span class="at">from =</span> <span class="dv">100</span>, <span class="at">to =</span> <span class="dv">250</span>)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.12-1.svg" width="672" /></p>
<p>The <span class="math inline">\(\sigma\)</span> prior is a truly flat prior.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dunif</span>(x, <span class="dv">0</span>, <span class="dv">50</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">60</span>)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.13-1.svg" width="672" /> A standard deviation like <span class="math inline">\(\sigma\)</span> must be positive, so bounding it at zero makes sense.</p>
<p><img src="slides/L03/27.png" width="60%" /></p>
<p>Before your model has seen the data. This is not p-hacking, because we’re not using the data. We’re using scientific information. All you have to sample values.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>sample_mu <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, <span class="dv">178</span>, <span class="dv">20</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>sample_sigma <span class="ot">=</span> <span class="fu">runif</span>(<span class="fl">1e4</span>, <span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>prior_h <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, sample_mu, sample_sigma)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(prior_h)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.14-1.svg" width="672" /> This is not a normal distribution. It’s a t-distribution because you have uncertainty about variance, which gives it fat tails. There are some really really tall individuals in this prior. But at least we don’t have any negative heights.</p>
<p>Let’s see the implied heights:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>sample_mu <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, <span class="dv">178</span>, <span class="dv">100</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>prior_h <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, sample_mu, sample_sigma)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(prior_h)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.15-1.svg" width="672" /></p>
<p>Before it even sees the data, it expects 4% of people to have negative height, and also some giants. Does it matter? In this case we have so much data that the silly prior is harmless. But that won’t always be the case. There are plenty of inference problems for which the data alone are not sufficient, no matter how numerous. Bayes lets us proceed in these cases, but only if we use our scientific knowledge to construct sensible priors. <em>The important thing is that your prior not be based on the values in the data, but only on what you know about the data before you see it.</em></p>
<p>Let’s use a different prior.</p>
<p><img src="slides/L03/28.png" width="60%" /></p>
<p>Typical linear regression priors are flat. They’re bad new because they create impossible outcomes before you even see the data.</p>
</div>
<div id="grid-approximation-of-the-posterior-distribution" class="section level3">
<h3>4.3.3. Grid approximation of the posterior distribution</h3>
<p><img src="slides/L03/29.png" width="60%" /></p>
<p>Once you start working with mixed models, the priors have a greater effect, so it’s good to get used to prior predictive simulation now.</p>
<p>We’ll calculate the grid and the posterior probability. How? Multiply the observed height conditional on the mu and sigma at that point. Times the prior probability of that mu and sigma. They code to do this is some loops.</p>
<p><img src="slides/L03/30.png" width="60%" /></p>
<p>100x100 you start to see the Gaussian hill. Gradually the values become increasingly implausible. What we do here is draw samples.</p>
<p>Here are the guts of the golem:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>mu.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">150</span>, <span class="at">to=</span><span class="dv">160</span> , <span class="at">length.out=</span><span class="dv">100</span> )</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>sigma.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">7</span> , <span class="at">to=</span><span class="dv">9</span> , <span class="at">length.out=</span><span class="dv">100</span> )</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>( <span class="at">mu=</span>mu.list , <span class="at">sigma=</span>sigma.list )</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>LL <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post) , <span class="cf">function</span>(i) <span class="fu">sum</span>(</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dnorm</span>( d2<span class="sc">$</span>height , post<span class="sc">$</span>mu[i] , post<span class="sc">$</span>sigma[i] , <span class="at">log=</span><span class="cn">TRUE</span> ) ) )</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>prod <span class="ot">&lt;-</span> post<span class="sc">$</span>LL <span class="sc">+</span> <span class="fu">dnorm</span>( post<span class="sc">$</span>mu , <span class="dv">178</span> , <span class="dv">20</span> , <span class="cn">TRUE</span> ) <span class="sc">+</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dunif</span>( post<span class="sc">$</span>sigma , <span class="dv">0</span> , <span class="dv">50</span> , <span class="cn">TRUE</span> )</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>prob <span class="ot">&lt;-</span> <span class="fu">exp</span>( post<span class="sc">$</span>prod <span class="sc">-</span> <span class="fu">max</span>(post<span class="sc">$</span>prod) )</span></code></pre></div>
<p>Inspect the posterior distribution</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">contour_xyz</span>(post<span class="sc">$</span>mu, post<span class="sc">$</span>sigma, post<span class="sc">$</span>prob)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.17-1.svg" width="672" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">image_xyz</span>(post<span class="sc">$</span>mu, post<span class="sc">$</span>sigma, post<span class="sc">$</span>prob)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.18-1.svg" width="672" /> ### 4.3.4. Sampling from the posterior</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>sample.rows <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post) , <span class="at">size=</span><span class="fl">1e4</span> , <span class="at">replace=</span><span class="cn">TRUE</span> , <span class="at">prob=</span>post<span class="sc">$</span>prob )</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sample.mu <span class="ot">&lt;-</span> post<span class="sc">$</span>mu[ sample.rows ]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>sample.sigma <span class="ot">&lt;-</span> post<span class="sc">$</span>sigma[ sample.rows ]</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( sample.mu , sample.sigma , <span class="at">cex=</span><span class="fl">0.5</span> , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span>rethinking<span class="sc">::</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.20-1.svg" width="672" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(sample.mu)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.21-1.svg" width="672" /></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(sample.sigma)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.21-2.svg" width="672" /> Summarise the widths:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">PI</span>(sample.mu)</span></code></pre></div>
<pre><code>##       5%      94% 
## 153.9394 155.2525</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">PI</span>(sample.sigma)</span></code></pre></div>
<pre><code>##       5%      94% 
## 7.323232 8.252525</code></pre>
<p><img src="slides/L03/31.png" width="60%" /></p>
<p>Once you have the samples, you just work with the data frame. You can look at cross-sections of this.</p>
<p>Note that this isn’t perfectly symmetrical for sigma - the right tail is longer. This is almost always true for SD parameters. Why? Because you know something about the SD before you see the data: you know it’s positive. So you always have more uncertainty on the higher end.</p>
<p>Let’s analyze only 20 of the heights from teh height data to reveal this issue.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">=</span> <span class="fu">sample</span>(d2<span class="sc">$</span>height, <span class="at">size =</span> <span class="dv">20</span>)</span></code></pre></div>
<p>Now repeat the code from the previous subsection, modified to focus on the 20 heights in <code>d3</code> rather than the original data.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>mu.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">150</span>, <span class="at">to=</span><span class="dv">170</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>sigma.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">4</span> , <span class="at">to=</span><span class="dv">20</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>post2 <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>( <span class="at">mu=</span>mu.list , <span class="at">sigma=</span>sigma.list )</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>LL <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post2) , <span class="cf">function</span>(i)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>( <span class="fu">dnorm</span>( d3 , <span class="at">mean=</span>post2<span class="sc">$</span>mu[i] , <span class="at">sd=</span>post2<span class="sc">$</span>sigma[i] ,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">log=</span><span class="cn">TRUE</span> ) ) )</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>prod <span class="ot">&lt;-</span> post2<span class="sc">$</span>LL <span class="sc">+</span> <span class="fu">dnorm</span>( post2<span class="sc">$</span>mu , <span class="dv">178</span> , <span class="dv">20</span> , <span class="cn">TRUE</span> ) <span class="sc">+</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dunif</span>( post2<span class="sc">$</span>sigma , <span class="dv">0</span> , <span class="dv">50</span> , <span class="cn">TRUE</span> )</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>prob <span class="ot">&lt;-</span> <span class="fu">exp</span>( post2<span class="sc">$</span>prod <span class="sc">-</span> <span class="fu">max</span>(post2<span class="sc">$</span>prod) )</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>sample2.rows <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post2) , <span class="at">size=</span><span class="fl">1e4</span> , <span class="at">replace=</span><span class="cn">TRUE</span> , <span class="at">prob=</span>post2<span class="sc">$</span>prob )</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>sample2.mu <span class="ot">&lt;-</span> post2<span class="sc">$</span>mu[ sample2.rows ]</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>sample2.sigma <span class="ot">&lt;-</span> post2<span class="sc">$</span>sigma[ sample2.rows ]</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( sample2.mu , sample2.sigma , <span class="at">cex=</span><span class="fl">0.5</span> ,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) ,</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;mu&quot;</span> , <span class="at">ylab=</span><span class="st">&quot;sigma&quot;</span> , <span class="at">pch=</span><span class="dv">16</span> )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.24-1.svg" width="672" /></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(sample2.sigma, <span class="at">norm.comp =</span> T)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.25-1.svg" width="672" /> Now you can see the posterior for <span class="math inline">\(\sigma\)</span> is not Gaussian, but as a long tail towards higher values.</p>
</div>
<div id="finding-the-posterior-distribution-with-quap" class="section level3">
<h3>4.3.5. Finding the posterior distribution with <code>quap</code></h3>
<p><img src="slides/L03/32.png" width="60%" /></p>
<p>Grid approximation is useful for teaching, but now we’ll do a fancy approximation of it so we can go to higher dimensions. THat approximation asserts that the distribution is normal for every parameter. But once you get to generalised linear models it’s a bad approximation. How does this work? You need two numbers: mean and SD. For multi-dimensional Gaussians, you also need a covariance matrix for the parameters. How do you do it? You climb the hill. It doesn’t know what the hill is, but it knows what is up and down. So it tries to find the peak. When it gets to the peak, it needs to measure the curvature of the peak. And that’s all it needs to approxi ate the curve. Often called the LaPlace approximation.</p>
<p>Repeat the code to load the data and select the adults:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[ d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span> , ]</span></code></pre></div>
<p><img src="slides/L03/33.png" width="60%" /></p>
<p><code>quap</code> works by making the formula lists. Typically there’s some abbreviated forms. You’ll have to write how every parameter multiplies every variable.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>flist <span class="ot">=</span> <span class="fu">alist</span>(</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  mu <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">20</span>),</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Plug in the parameters and plug it into <code>quap</code>.</p>
<p><img src="slides/L03/34.png" width="60%" /></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.1</span> <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">quap</span>(flist, <span class="at">data =</span> d2)</span></code></pre></div>
<p><code>quap</code> translates it into a statement about a log probability of the combinations of data, then passes it to the hill-finding algorithm built into R called <code>optim</code>, which passes it back as a list of means and a covariance matrix, which is sufficient to create a posterior distribution.</p>
<p><img src="slides/L03/35.png" width="60%" /></p>
<p><code>precis</code> is minimalistic compared to <code>summary</code>. Provides the 89% compatibility intervals.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">precis</span>(m4<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##            mean        sd       5.5%      94.5%
## mu    154.60678 0.4119987 153.948324 155.265231
## sigma   7.73141 0.2913933   7.265707   8.197113</code></pre>
<p>These numbers provide Gaussian approximations for each parameter’s <em>marginal</em> distribution, meaning the plausibility of each value of <span class="math inline">\(\mu\)</span> after averaging over the plausibilities of each value of <span class="math inline">\(\sigma\)</span>.</p>
<p><code>quap</code> estimates the posterior by climbing it like a hill. To do this, it has to start climbing someplace, at some combination of parameter values. But it’s possible to specify a starting value</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu=</span><span class="fu">mean</span>(d2<span class="sc">$</span>height),</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma=</span><span class="fu">sd</span>(d2<span class="sc">$</span>height)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>( flist , <span class="at">data=</span>d2 , <span class="at">start=</span>start )</span></code></pre></div>
<p>Let’s splice in a more informative prior for <span class="math inline">\(\mu\)</span> so you can see the effect.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="fl">0.1</span> ) ,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d2 )</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m4<span class="fl">.2</span> )</span></code></pre></div>
<pre><code>##            mean        sd      5.5%     94.5%
## mu    177.86375 0.1002354 177.70356 178.02395
## sigma  24.51756 0.9289235  23.03297  26.00216</code></pre>
</div>
<div id="sampling-from-a-quap" class="section level3">
<h3>4.3.6. Sampling from a <code>quap</code></h3>
<p>To this the matrix of variances and covariances among all paris of parameters:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">vcov</span>(m4<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##                 mu        sigma
## mu    0.1697396109 0.0002180307
## sigma 0.0002180307 0.0849058224</code></pre>
<p>This is a <strong>Variant-covariance Matrix</strong>. It is the multi-dimensional glue of a quadratic approximation, because it tells us how each parameter relates to every other parameter in the posterior distribution.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(rethinking<span class="sc">::</span><span class="fu">vcov</span>( m4<span class="fl">.1</span> ))</span></code></pre></div>
<pre><code>##         mu      sigma 
## 0.16973961 0.08490582</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cov2cor</span>(rethinking<span class="sc">::</span><span class="fu">vcov</span>( m4<span class="fl">.1</span> ) )</span></code></pre></div>
<pre><code>##                mu       sigma
## mu    1.000000000 0.001816174
## sigma 0.001816174 1.000000000</code></pre>
<p><img src="slides/L03/36.png" width="60%" /></p>
<p>Compare <code>quap</code> to grid approximation. The values in the rows go together. But plot the columns by themselves. Sigma still has a skew.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">extract.samples</span>(m4<span class="fl">.1</span>, <span class="at">n =</span> <span class="fl">1e4</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(post)</span></code></pre></div>
<pre><code>##         mu    sigma
## 1 154.3996 7.844182
## 2 154.2124 8.086808
## 3 153.9507 8.025614
## 4 154.5828 8.153164
## 5 155.1950 7.687962
## 6 155.1171 7.753253</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(post)</span></code></pre></div>
<pre><code>##             mean        sd       5.5%      94.5%    histogram
## mu    154.609679 0.4064340 153.955863 155.262132      ▁▁▅▇▂▁▁
## sigma   7.728974 0.2924447   7.262134   8.193688 ▁▁▁▂▅▇▇▃▁▁▁▁</code></pre>
<p>Here’s a peak under the motor of <code>extract.samples</code>:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">=</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(<span class="at">n =</span> <span class="fl">1e4</span>, <span class="at">mu =</span> <span class="fu">coef</span>(m4<span class="fl">.1</span>), <span class="at">Sigma =</span> <span class="fu">vcov</span>(m4<span class="fl">.1</span>))</span></code></pre></div>
<p><img src="slides/L03/37.png" width="60%" /></p>
<p>To find out what it means, you draw some lines. I think of this tool as a scaffold so you can learn how to do modelling. But after you can use packages that use abbreviations. But it’s important to learn how to build them. You’ll come to appreciate how explicit it is.</p>
<p>You want to graduate beyond <code>quap</code> because for generalised linear modelling it becomes dangerous.</p>
</div>
</div>
<div id="linear-prediction" class="section level2">
<h2>4.4. Linear prediction</h2>
<p>Let’s look at how height in these Kalahari foragers covaries with weight.</p>
<p><img src="slides/L03/38.png" width="60%" /></p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1); d <span class="ot">&lt;-</span> Howell1; d2 <span class="ot">&lt;-</span> d[ d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span> , ]</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( d2<span class="sc">$</span>height <span class="sc">~</span> d2<span class="sc">$</span>weight )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.37-1.svg" width="672" /></p>
<p>So now let’s add a line. When we learn the predictions, we can learn the statistical association between weight and height. The question is how would you statistically describe this relationship?</p>
<div id="the-linear-model-strategy" class="section level3">
<h3>4.14.1. The linear model strategy</h3>
<p><img src="slides/L03/39.png" width="60%" /></p>
<p>So what do we do? We add another variable to the model, and now we have a linear regression. This model has all the standard features. Now there’s an <span class="math inline">\(i\)</span> on <span class="math inline">\(mu\)</span>. That means it’s different for each person. <span class="math inline">\(alpha\)</span> is out population mean. <span class="math inline">\(beta\)</span> describes the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p><img src="slides/L03/40.png" width="60%" /></p>
<p>The equals sign mean that it’s deterministically defined. <span class="math inline">\(beta\)</span> is what you’d call a slope, or the rate of change in <span class="math inline">\(mu\)</span> for a unit change in <span class="math inline">\(x\)</span>. Why do we subtract x bar? This is called centering the predictor. Should be your default behaviour.</p>
<p><img src="slides/L03/41.png" width="60%" /></p>
<p>It’s now predicting lines. So what does the prior predictive distribution look like? A whole lot of lines.</p>
<p><img src="slides/L03/42.png" width="60%" /></p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2971</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">=</span> <span class="dv">100</span> <span class="co"># 100 lines</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">rnorm</span>(N, <span class="dv">178</span>, <span class="dv">20</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">10</span>)</span></code></pre></div>
<p>Now we have 100 paris of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> values.</p>
<p>Simulate 100 lines as before.</p>
<p><img src="slides/L03/43.png" width="60%" /></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="cn">NULL</span> , <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>,<span class="dv">400</span>), <span class="at">xlab=</span><span class="st">&quot;weight&quot;</span> , <span class="at">ylab=</span><span class="st">&quot;height&quot;</span> )</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h=</span><span class="dv">0</span> , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h=</span><span class="dv">272</span> , <span class="at">lty=</span><span class="dv">1</span> , <span class="at">lwd=</span><span class="fl">0.5</span> )</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">&quot;b ~ dnorm(0,10)&quot;</span> )</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N ) <span class="fu">curve</span>( a[i] <span class="sc">+</span> b[i]<span class="sc">*</span>(x <span class="sc">-</span> xbar),</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">from=</span><span class="fu">min</span>(d2<span class="sc">$</span>weight) ,</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">to=</span><span class="fu">max</span>(d2<span class="sc">$</span>weight) , <span class="at">add=</span><span class="cn">TRUE</span> ,</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">&quot;black&quot;</span>,<span class="fl">0.2</span>) )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.39-1.svg" width="672" /></p>
<p>Getting the scatter right is important, because you can see these impossibly steep lines. Some of them take you from impossibly short individuals to twice the tallest. Want to dampen these expectations. Practise on these safe examples.</p>
<p><img src="slides/L03/44.png" width="60%" /></p>
<p>We know that <span class="math inline">\(beta\)</span> is positive, so let’s make it positive. A log normal distribution is a normal distribution logged. What’s nice is that they’re all positive. We want to assume the relationship between weight and height is positive.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">rlnorm</span>(<span class="fl">1e4</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(b, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">5</span>), <span class="at">adj =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.40-1.svg" width="672" /></p>
<p><img src="slides/L03/45.png" width="60%" /></p>
<p>Still a lot of scatter, but still one crazy line. Now at least we’re in the possible range.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2971</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># 100 lines</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( N , <span class="dv">178</span> , <span class="dv">20</span> )</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>( N , <span class="dv">0</span> , <span class="dv">1</span> )</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="cn">NULL</span> , <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">100</span>,<span class="dv">400</span>), <span class="at">xlab=</span><span class="st">&quot;weight&quot;</span> , <span class="at">ylab=</span><span class="st">&quot;height&quot;</span> )</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h=</span><span class="dv">0</span> , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">h=</span><span class="dv">272</span> , <span class="at">lty=</span><span class="dv">1</span> , <span class="at">lwd=</span><span class="fl">0.5</span> )</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">&quot;b ~ dnorm(0,10)&quot;</span> )</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N ) <span class="fu">curve</span>( a[i] <span class="sc">+</span> b[i]<span class="sc">*</span>(x <span class="sc">-</span> xbar),</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>                        <span class="at">from=</span><span class="fu">min</span>(d2<span class="sc">$</span>weight) ,</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>                        <span class="at">to=</span><span class="fu">max</span>(d2<span class="sc">$</span>weight) , <span class="at">add=</span><span class="cn">TRUE</span> ,</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>                        <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">&quot;black&quot;</span>,<span class="fl">0.2</span>) )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.41-1.svg" width="672" /> &gt; How to choose a prior? The procedure we’ve performed in this chapter is to choose priors conditional on pre-data knowledge of the variables - their constraints, ranges, and theoretical relationships.</p>
</div>
<div id="finding-the-posterior-distribution" class="section level3">
<h3>4.4.2. Finding the posterior distribution</h3>
<p><img src="slides/L03/46.png" width="60%" /></p>
<p>Measure xbar. Then define the <code>quap</code> model. Focus on the <span class="math inline">\(mu\)</span> line.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load data again, since it&#39;s a long way back</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1); d <span class="ot">&lt;-</span> Howell1; d2 <span class="ot">&lt;-</span> d[ d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span> , ]</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># define the average weight, x-bar</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>( weight <span class="sc">-</span> xbar ) ,</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">20</span> ) ,</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dlnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d2 )</span></code></pre></div>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.3</span>b <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> <span class="fu">exp</span>(log_b)<span class="sc">*</span>( weight <span class="sc">-</span> xbar ),</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">20</span> ) ,</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    log_b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span>),</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d2 )</span></code></pre></div>
</div>
<div id="interpreting-the-posterior-distribution" class="section level3">
<h3>4.4.3. Interpreting the posterior distribution</h3>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>##              mean         sd        5.5%       94.5%
## a     154.6013671 0.27030766 154.1693633 155.0333710
## b       0.9032807 0.04192363   0.8362787   0.9702828
## sigma   5.0718809 0.19115478   4.7663786   5.3773831</code></pre>
<p>See the covariances</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(rethinking<span class="sc">::</span><span class="fu">vcov</span>(m4<span class="fl">.3</span>), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##           a     b sigma
## a     0.073 0.000 0.000
## b     0.000 0.002 0.000
## sigma 0.000 0.000 0.037</code></pre>
<p>Very little covariation among the parameters in this case.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show both the marginal posteriors and the covariance</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(m4<span class="fl">.3</span>)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/unnamed-chunk-48-1.svg" width="672" /> In the practice problems at the end of the chapter, you’ll see that the lack of covariance among the parameters results from <strong>Centering</strong>.</p>
<p>Plot the data with the posterior mean values for <code>a</code> and <code>b</code>:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>d2 , <span class="at">col=</span>rangi2 )</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m4<span class="fl">.3</span> )</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>a_map <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>a)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>b_map <span class="ot">&lt;-</span> <span class="fu">mean</span>(post<span class="sc">$</span>b)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( a_map <span class="sc">+</span> b_map<span class="sc">*</span>(x <span class="sc">-</span> xbar) , <span class="at">add=</span><span class="cn">TRUE</span> )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.46-1.svg" width="672" /></p>
<p><img src="slides/L03/47.png" width="60%" /></p>
<p>We managed to get this posterior distribution, and we can take from the precis values the <code>a</code> and <code>b</code>b values and draw a line with those, where <code>a</code> is the expected value of height (155) when weight is at its average value. And the expected change in height is nearly 1. But the posterior distribution is not a single line, it’s an infinite number of lines each with a probability. So let’s get more lines on the graph to show the uncertainty in inference.</p>
<p><img src="slides/L03/48.png" width="60%" /></p>
<p>Here’s the basic idea. We’re going to sample from the posterior distribution. But what’s great is that you can use this process for any model you ever want to fit. You can sample from the posterior, then push the samples back through the model itself to plot the uncertainty.</p>
<p><img src="slides/L03/49.png" width="60%" /> You’re doing calculus here, but just doesn’t feel like it. Each row is a line. Lines that are more plausible have more ways to happen, so they’re overlap more in the areas that are more plausible.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">extract.samples</span>(m4<span class="fl">.3</span>)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>post[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, ]</span></code></pre></div>
<pre><code>##          a         b    sigma
## 1 154.4622 0.9150822 5.341227
## 2 154.2649 0.9236067 5.160423
## 3 155.1258 0.9495934 5.108891
## 4 154.5923 0.8458252 4.994873
## 5 154.2600 0.9065280 5.110351</code></pre>
<p><img src="slides/L03/50.png" width="60%" /></p>
<p>To see this work, and reinforce how Bayesian updating works, let’s start with a reduced dataset of 10 randomly sampled adults. We fit our linear regression model, and get a quadratic approximation of the posterior distribution. You’ll see they’re very different from the prior. Now they’re very concentrated around the data. You can see there’s a lot of scatter because the model isn’t sure where it should be.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>dN <span class="ot">&lt;-</span> d2[ <span class="dv">1</span><span class="sc">:</span>N , ]</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>mN <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>( weight <span class="sc">-</span> <span class="fu">mean</span>(weight) ) ,</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">20</span> ) ,</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dlnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>dN )</span></code></pre></div>
<p>Now plot 20 of these lines:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract 20 samples from the posterior</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( mN , <span class="at">n=</span><span class="dv">20</span> )</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># display raw data and sample size</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( dN<span class="sc">$</span>weight , dN<span class="sc">$</span>height ,</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">range</span>(d2<span class="sc">$</span>height) ,</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col=</span>rangi2 , <span class="at">xlab=</span><span class="st">&quot;weight&quot;</span> , <span class="at">ylab=</span><span class="st">&quot;height&quot;</span> )</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">&quot;N = &quot;</span>,N))</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the lines, with transparency</span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span> )</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">curve</span>( post<span class="sc">$</span>a[i] <span class="sc">+</span> post<span class="sc">$</span>b[i]<span class="sc">*</span>(x<span class="sc">-</span><span class="fu">mean</span>(dN<span class="sc">$</span>weight)) ,</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">&quot;black&quot;</span>,<span class="fl">0.3</span>) , <span class="at">add=</span><span class="cn">TRUE</span> )</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.49-1.svg" width="672" /></p>
<p><img src="slides/L03/51.png" width="60%" /> Now add 50, and you’ll see they get more concentrated. Note the uncertainty at the ends are more uncertain. They pivot around the means in the centre.</p>
<p><img src="slides/L03/52.png" width="60%" /></p>
<p><img src="slides/L03/53.png" width="60%" /></p>
<p>With the whole dataset, it gets quite narrow. You constrained the model to pick a line, and these are the lines that it likes. Doesn’t mean that it’s right.</p>
<hr />
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>slides_dir <span class="ot">=</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;docs/slides/L04&quot;</span>)</span></code></pre></div>
<p><img src="slides/L04/01.png" width="60%" /></p>
<p><img src="slides/L04/09.png" width="60%" /></p>
<p>The basic idea that any particular value of the <span class="math inline">\(x\)</span> variables, <span class="math inline">\(mu\)</span> has some density. It’s confident of the values on the inside, less of the values on the outside. As an example, what does the model expect the height of the individual is if weight is 50? <span class="math inline">\(mu\)</span> at 50 is now going to create a distribution.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">extract.samples</span>(m4<span class="fl">.3</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>mu_at_50 <span class="ot">=</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> (<span class="dv">50</span> <span class="sc">-</span> xbar)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mu_at_50)</span></code></pre></div>
<pre><code>## [1] 159.0740 159.4226 158.9418 159.2489 159.2202 159.2177</code></pre>
<p><code>mu_at_50</code> is a vector of predicted means, one for each random sample from the posterior.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(mu_at_50, <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">xlab =</span> <span class="st">&quot;mu|weight = 50&quot;</span>)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.51-1.svg" width="672" /> Find the 89% compatibility interval</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">PI</span>(mu_at_50, <span class="at">prob =</span> .<span class="dv">89</span>)</span></code></pre></div>
<pre><code>##       5%      94% 
## 158.5785 159.6799</code></pre>
<p><img src="slides/L04/10.png" width="60%" /></p>
<p>It’s not sure how tall an individual is, but it thinks it’s in this region. But we want to do this for every x-axis value. This is what produces the smooth bowtie.</p>
<p><img src="slides/L04/11.png" width="60%" /></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">link</span>(m4<span class="fl">.3</span>)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu)</span></code></pre></div>
<pre><code>##  num [1:1000, 1:352] 157 157 157 157 157 ...</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">dens</span>(mu)</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.53-1.svg" width="672" /></p>
<p>You need to make a sequence of x-axis values (<code>weight.seq</code>). You could make it extraplote further if you like. Then you send these in to the funciton via <code>link</code>. There’s a box in the chapter that shows you how link works. It just loops, but saves you time.</p>
<p>What you end up with in <span class="math inline">\(m\)</span> is 1000 rows, where each column is a value of weight. Then you can plot these up.</p>
<p>There are 352 rows in <code>d2</code>, corresponding to 352 individuals. What to do with this big matrix? <code>link</code> provides a posterior distribution of <span class="math inline">\(\mu\)</span> for each case we feed it. We actually want a distribution of <span class="math inline">\(\mu\)</span> for each unique weight value on the horizontal axis. Just pass it some new data:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define sequence of weights to compute predictions for</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># these vaules will be on the horizontal axis</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">=</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">25</span>, <span class="at">to =</span> <span class="dv">70</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="co"># use link to compute mu</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a><span class="co"># for each sample from posterior</span></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and for each weight in weight.seq</span></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> rethinking<span class="sc">::</span><span class="fu">link</span>(m4<span class="fl">.3</span>, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">weight =</span> weight.seq))</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu)</span></code></pre></div>
<pre><code>##  num [1:1000, 1:46] 136 137 137 136 137 ...</code></pre>
<p>And now there are only 46 columns in <code>mu</code>, because we fed it 46 different values for <code>weight</code>. Let’s plot the distribution:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use type=&quot;n&quot; to hide raw data</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, d2, <span class="at">type =</span> <span class="st">&quot;n&quot;</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over samples and plot each mu value</span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(weight.seq, mu[i,] , <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, .<span class="dv">1</span>))</span></code></pre></div>
<p><img src="04_geocentric_models_files/figure-html/4.55-1.svg" width="672" /></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize the distribution of mu</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">=</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">=</span>  <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> .<span class="dv">89</span>)</span></code></pre></div>
<p><img src="slides/L04/12.png" width="60%" /></p>
<p>This is like rolling your own <code>link</code> here.</p>
<p><img src="slides/L04/13.png" width="60%" /></p>
<p>Think what’s going on with the distribution. Fuzzy bowtie. There’s a grey bowtie on the right that follows the same distribution on the left. Just comes from plotting the compatibility interval of the bowtie.</p>
<p><img src="slides/L04/14.png" width="60%" /></p>
<p>Again, there’s a correspondence between the spaghetti lines, and the bowtie form… <img src="slides/L04/15.png" width="60%" /> Same information, just a different visual style.</p>
<p>One benefit of the spaghetti lines is it prevents you from thinking the boundary is some magical event. Nothing happens at that boundary. Probability is a continuous space.</p>
<p><img src="slides/L04/16.png" width="60%" /></p>
<p>We can do the same thing for sigma. There’s an envelope we expect heights to be in.</p>
<p>Helper function called <code>sim</code> that shows conceptually what’s happening.</p>
<p><img src="slides/L04/17.png" width="60%" /> That’s linear regression. The funny thing about it is not linear. Really linear regression is additive. You have an equation for <span class="math inline">\(mu\)</span> which is a sum of a bunch of variables. We should call these additive regressions because you can use them to draw “lines” i.e. curves from lines. Why? There’s no reason that nature should be populated by straight-line relationships. We routinely have reason to think about curvo-linear relationship.</p>
<p>There are common strategies. The two most common are polynomial regression - the most common - involves adding a square term. Also pretty bad. Often it’s used irresponsibly.</p>
<p>The second is splines. Basis splines, probably the most common. Computer drawing software uses these. They don’t exhibit the common pathologies of polynomials. But remember that they’re geocentric models. So when you receive the information from the model, there’s nothing mechanistic about this, and they can exhibit very strange behaviour outside of the range of the data.</p>
<p><img src="slides/L04/18.png" width="60%" /> This is a descriptive strategy for drawing curves for the relationship between two variables. Second-order gives you a parabola. You can keep going - third order, fourth order. And on and on and on. You can push this to the limits of absurdity.</p>
<p><img src="slides/L04/19.png" width="60%" /> The data we’re going to use is the total sample. Now we’ll use the kids. Looking at this you can appreciate this isn’t a line. Instead, let’s fit a parabola.</p>
<p><img src="slides/L04/20.png" width="60%" /> We can just glue on an epicycle here and square it. Why? So alpha can be the mean. Then you need to give it a new <span class="math inline">\(\beta\)</span> coefficient. Setting priors for this is really hard, because <span class="math inline">\(\beta_2\)</span> has no meaning. But the curve depends on <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>, and they don’t work in isolation. The individual parameters don’t have meaning. It’s a horrible problem in interpretation. Otherwise it’s the same model. It’s a linear regression in the sense that it’s additive.</p>
<p><img src="slides/L04/21.png" width="60%" /></p>
<p>To get the machine to work, very useful to standardise the predictor variables. Center then divide by SD. Take weight, subtract the average weight from each weight value, then divide each of those 0-centered values by the standard deviation of weight. Takes weight and creates a set of z-scores. The fitting software works better on standardise values because it doesn’t have to guess the scale.</p>
<p><img src="slides/L04/22.png" width="60%" /></p>
<p>There’s a function in R called <code>scale</code>. All it does is subtract the mean, then divide by the standard deviation. Square the standardised weight.</p>
<p><img src="slides/L04/23.png" width="60%" /> Cooked spaghetti. Now it has an infinite number of parabolas. Now we sample from the posterior, and we got a sample of the high-probability parabolas, a tiny slice of the whole space. And we draw them up, to start with, just 10 individuals. Over the full range, we get parabolas that vary wildly outside of the weights, but straight within the range of the data. This is a phenomenon that’s always present. THe uncertainty intervals always fan out outside of the data range. This is a problem for prediction. Not true for splines. This is because every parameter acts globally on the shape. You can’t tune a specfic region.</p>
<p><img src="slides/L04/24.png" width="60%" /></p>
<p>Now we add the next 10, including some children, and the flailing stops. Now we get curves in a much smaller region of the parameter space.</p>
<p><img src="slides/L04/25.png" width="60%" /> Now it’s getting more concentrated. <img src="slides/L04/26.png" width="60%" /></p>
<p><img src="slides/L04/27.png" width="60%" /></p>
<p><img src="slides/L04/28.png" width="60%" /></p>
<p>Now a thick dark line. Conditional on wanting a parabola to describe the relationship, here are the parabolas. Doesn’t mean the parabola is correct. <img src="slides/L04/29.png" width="60%" /></p>
<p>It’s very sure, conditional on the shape, that that’s the parameter you want. Those lines don’t fit the data very well, but there’s almost no uncertainty about where they are.</p>
<p>I’ve extended the data a bit, and you can see the quadratic bends down. It curves down because it has to. Cubic have to turn twice. Have to turn. Can’t be <em>monotonic</em>.</p>
<p>For the cubic, we add our cubic term <span class="math inline">\(\beta_3\)</span>. Fits even better, but now it’s extrapolating upwards.</p>
<p><img src="slides/L04/30.png" width="60%" /></p>
<p>In this example, you had that outside of the range below the range. But this can also happen internally, when you have a gap in your data, and it’ll do silly things in between.</p>
<p>The bigger problem is that the parameters all jointly determine the shape, so the model can’t tune them independently to create local fits. That’s why you get silly predictions. Polynomials aren’t that flexible, because the <em>must</em> turn, a certain number of times.</p>
<p><img src="slides/L04/31.png" width="60%" /></p>
<p>A common alternative is another geocentric model, which is also satisfying because it’s born from a physical system used to do the same thing. A spline is this metal bar on the draftsman’s table. It bends the line to allow drafters to draw smooth curves. This things still exist. The spline is the bar, and the weights are anchors, <em>knots</em>.</p>
<p><img src="slides/L04/32.png" width="60%" /> You can get a globally very wiggly function, with a bunch of local wiggly functions by putting them together. Very good for extrapolating. But remember they’re geocentric, so you have to understand how they work.</p>
<p>The basis function is a local function, and the spline is made up of interpolating basis functions. Basis = “component”. Big wiggly function made up of less wiggly functions.</p>
<p>The “P” stands for “penalised”.</p>
<p><img src="slides/L04/33.png" width="60%" /></p>
<p>Again, it’s a linear model, an additive equation for <span class="math inline">\(\mu\)</span>. But the predictor variables are not observed, rather synthetic data that defines the range of the curve that the parameter acts in. The actual predictor of interest will not appear in your model, but you’ll get a fantastic predictor of the relationship between the variables.</p>
<p>There will be one weight for each of the basis functions. And the weights affect the range defined by the <span class="math inline">\(\beta\)</span> variables.</p>
<p><img src="slides/L04/34.png" width="60%" /> New example. Let’s find something very wiggly. Climate data. Date of first cherry blossom bloom. Turns out there’s a very interesting relationship between the date of bloom, and the temperature. Big signature of climate change in this data.</p>
<p><img src="slides/L04/35.png" width="60%" /></p>
<p>1215 observations. Earliest date is little after 800. A few gaps. Earlier dates are getting temps from tree rings. Wiggles a lot. You can see there’s overlap. You’ll recognise the end of this trend. Our goal is to de-trend this temperature record. We want to look at micro-deviations.</p>
<p><img src="slides/L04/36.png" width="60%" /> Let’s start with a terrible approximation, and work forwards.</p>
<p>Here’s the recipe. First choose the location of the knots. Here they are points where the basis spline pivots. Choose a degree of the basis function. Then choose degree of local spline. Then find the posterior distribution of weights. Run this just like any old linear regression.</p>
<p><img src="slides/L04/37.png" width="60%" /> Start with just 5 knots at equal quantiles. Large literature on this. Nice because it gives you more knots where there’s more data. One at the median, then one at each extreme, and one in between.</p>
<p><img src="slides/L04/38.png" width="60%" /> Let’s think about construction of these synthetic variables. Think of year. We’ll never use them again. The knots are anchored at year, but then they’re gone. Start with a degree 1 basis function (i.e. straight line). Wiggly function composed of straight line. Focus on the one in red. Basis fucntion 4 has its maximum value at the fourth knot. Only basis function with a non-zero value at that location. It’s weight is determining the position of the spline at that point. As you move away, there are two basis functions that are turning on. Each of them have they’re own precious parameter value.</p>
<p>When you get to higher degress, they’ll be curves. At any particular point (except at a knot), two of these basis functions will determine the value.</p>
<p><img src="slides/L04/39.png" width="60%" /></p>
<p>The only new trick here is to use linear algebra. You can imagine writing 5 terms.</p>
<p>We have a prior for each of the weights. If you make it tighter, the curve gets less wiggly, and that’s why they call it a penalty. You want one so that you don’t <em>overfit</em>.</p>
<p><img src="slides/L04/40.png" width="60%" /></p>
<p>Repeating the equation for <span class="math inline">\(\mu\)</span>. Showing you the posterior mean weights multiplied by those basis functions. That’s what the predictor up top is. Focusing on the posteriro mean. There’s uncertainty here. What happens now is you’re adding those values together. Two lines get added together, and that determines prediction of temperature.</p>
<p><img src="slides/L04/41.png" width="60%" /></p>
<p>Resulting spline isn’t super wiggly. Depends on what you want to de-trend.</p>
<p><img src="slides/L04/42.png" width="60%" /></p>
<p>Let’s do cubic splines. Most popular because they’re flexible but not crazy. Play around with the number of knots. What you’ll see is you can have too few knots, but at some point you’ll have enough that it won’t make much of a difference. This is what the basis functions look like, and now they’re wigglier, but they also overlap more, so now at a particular point you can have up to four basis curves overlapping.</p>
<p><img src="slides/L04/43.png" width="60%" /> Here’s with 50 samples from the posterior distribution. There’s all this wiggle, and you add them together and get the spline. Some of these regions have substantial uncertainty about the weight. The uncertainty will collapse. At the parameter level, there’s more uncertainty than there is at the prediction level. This is because the parameters combine to make a prediction. You can be uncertain about the values of the parameters, but you can be very certain about they’re sum. Because if you make <span class="math inline">\(w_3\)</span> bigger, you have to make something else smaller. So when you plot the parameters, you’ll see a lot more uncertainty than the predictions.</p>
<p><img src="slides/L04/44.png" width="60%" /></p>
<p>Now when we add them, we get a pretty wiggly line. The amount of wiggliness depends on your scale of interest.</p>
<p>Play around with the knots and degree and priors.</p>
<p><img src="slides/L04/45.png" width="60%" /> Lots of different methods. There are ways of doing Bayesian splines where the number of knots is a parameter you can get a posterior distribution for. Why not just have a knot at every year.</p>
<p><img src="slides/L04/46.png" width="60%" /></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
