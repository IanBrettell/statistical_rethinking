<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.1 Multicollinearity | Notes for Statistical Rethinking 2nd ed. by Richard McElreath" />
<meta property="og:type" content="book" />






<meta name="date" content="2021-06-22" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="6.1 Multicollinearity | Notes for Statistical Rethinking 2nd ed. by Richard McElreath">

<title>6.1 Multicollinearity | Notes for Statistical Rethinking 2nd ed. by Richard McElreath</title>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#index">Index</a></li>
<li><a href="1-the-golem-of-prague.html#the-golem-of-prague"><span class="toc-section-number">1</span> The Golem of Prague</a></li>
<li><a href="2-small-worlds-and-large-worlds.html#small-worlds-and-large-worlds"><span class="toc-section-number">2</span> Small Worlds and Large Worlds</a>
<ul>
<li><a href="2-1-the-garden-of-forking-data.html#the-garden-of-forking-data"><span class="toc-section-number">2.1</span> The garden of forking data</a></li>
<li><a href="2-2-building-a-model.html#building-a-model"><span class="toc-section-number">2.2</span> Building a model</a></li>
<li><a href="2-3-components-of-the-model.html#components-of-the-model"><span class="toc-section-number">2.3</span> Components of the model</a></li>
<li><a href="2-4-making-the-model-go.html#making-the-model-go"><span class="toc-section-number">2.4</span> Making the model go</a></li>
</ul></li>
<li><a href="3-sampling-from-the-imaginary.html#sampling-from-the-imaginary"><span class="toc-section-number">3</span> Sampling from the Imaginary</a>
<ul>
<li><a href="3-1-sampling-from-a-grid-approximate-posterior.html#sampling-from-a-grid-approximate-posterior"><span class="toc-section-number">3.1</span> Sampling from a grid-approximate posterior</a></li>
<li><a href="3-2-sampling-to-summarize.html#sampling-to-summarize"><span class="toc-section-number">3.2</span> Sampling to summarize</a></li>
<li><a href="3-3-sampling-to-simulate-prediction.html#sampling-to-simulate-prediction"><span class="toc-section-number">3.3</span> Sampling to simulate prediction</a></li>
<li><a href="practice.html#practice">Practice</a></li>
<li><a href="homework-week-1.html#homework-week-1">Homework: week 1</a></li>
</ul></li>
<li><a href="4-geocentric-models.html#geocentric-models"><span class="toc-section-number">4</span> Geocentric Models</a>
<ul>
<li><a href="4-1-why-normal-distributions-are-normal.html#why-normal-distributions-are-normal"><span class="toc-section-number">4.1</span> Why normal distributions are normal</a></li>
<li><a href="4-2-a-language-for-describing-models.html#a-language-for-describing-models"><span class="toc-section-number">4.2</span> A language for describing models</a></li>
<li><a href="4-3-gaussian-model-of-height.html#gaussian-model-of-height"><span class="toc-section-number">4.3</span> Gaussian model of height</a></li>
<li><a href="4-4-linear-prediction.html#linear-prediction"><span class="toc-section-number">4.4</span> Linear prediction</a></li>
<li><a href="4-5-curves-from-lines.html#curves-from-lines"><span class="toc-section-number">4.5</span> Curves from lines</a></li>
<li><a href="4-6-practice-1.html#practice-1"><span class="toc-section-number">4.6</span> Practice</a></li>
</ul></li>
<li><a href="5-the-many-variables-the-spurious-waffles.html#the-many-variables-the-spurious-waffles"><span class="toc-section-number">5</span> The Many Variables &amp; The Spurious Waffles</a>
<ul>
<li><a href="5-1-spurious-association.html#spurious-association"><span class="toc-section-number">5.1</span> Spurious association</a></li>
<li><a href="5-2-masked-relationship.html#masked-relationship"><span class="toc-section-number">5.2</span> Masked relationship</a></li>
<li><a href="5-3-categorical-variables.html#categorical-variables"><span class="toc-section-number">5.3</span> Categorical variables</a></li>
<li><a href="5-4-practice-2.html#practice-2"><span class="toc-section-number">5.4</span> Practice</a></li>
</ul></li>
<li><a href="6-the-haunted-dag-the-causal-terror.html#the-haunted-dag-the-causal-terror"><span class="toc-section-number">6</span> The Haunted DAG &amp; The Causal Terror</a>
<ul>
<li><a href="6-1-multicollinearity.html#multicollinearity"><span class="toc-section-number">6.1</span> Multicollinearity</a></li>
<li><a href="6-2-post-treatment-bias.html#post-treatment-bias"><span class="toc-section-number">6.2</span> Post-treatment bias</a></li>
<li><a href="6-3-collider-bias.html#collider-bias"><span class="toc-section-number">6.3</span> Collider bias</a></li>
<li><a href="6-4-confronting-confounding.html#confronting-confounding"><span class="toc-section-number">6.4</span> Confronting confounding</a></li>
<li><a href="6-5-summary.html#summary"><span class="toc-section-number">6.5</span> Summary</a></li>
<li><a href="6-6-practice-3.html#practice-3"><span class="toc-section-number">6.6</span> Practice</a></li>
</ul></li>
<li><a href="7-ulysses-compass.html#ulysses-compass"><span class="toc-section-number">7</span> Ulysses’ Compass</a>
<ul>
<li><a href="7-1-the-problem-with-parameters.html#the-problem-with-parameters"><span class="toc-section-number">7.1</span> The problem with parameters</a></li>
<li><a href="7-2-entropy-and-accuracy.html#entropy-and-accuracy"><span class="toc-section-number">7.2</span> Entropy and accuracy</a></li>
<li><a href="7-3-golem-taming-regularization.html#golem-taming-regularization"><span class="toc-section-number">7.3</span> Golem taming: regularization</a></li>
<li><a href="7-4-predicting-predictive-accuracy.html#predicting-predictive-accuracy"><span class="toc-section-number">7.4</span> Predicting predictive accuracy</a></li>
<li><a href="7-5-model-comparison.html#model-comparison"><span class="toc-section-number">7.5</span> Model comparison</a></li>
<li><a href="7-6-practice-4.html#practice-4"><span class="toc-section-number">7.6</span> Practice</a></li>
</ul></li>
<li><a href="8-conditional-manatees.html#conditional-manatees"><span class="toc-section-number">8</span> Conditional Manatees</a></li>
<li><a href="9-markov-chain-monte-carlo.html#markov-chain-monte-carlo"><span class="toc-section-number">9</span> Markov Chain Monte Carlo</a></li>
<li><a href="10-big-entropy-and-the-generalized-linear-model.html#big-entropy-and-the-generalized-linear-model"><span class="toc-section-number">10</span> Big Entropy and the Generalized Linear Model</a></li>
<li><a href="11-god-spiked-the-integers.html#god-spiked-the-integers"><span class="toc-section-number">11</span> God Spiked the Integers</a></li>
<li><a href="12-monsters-and-mixtures.html#monsters-and-mixtures"><span class="toc-section-number">12</span> Monsters and Mixtures</a></li>
<li><a href="13-models-with-memory.html#models-with-memory"><span class="toc-section-number">13</span> Models With Memory</a></li>
<li><a href="14-adventures-in-covariance.html#adventures-in-covariance"><span class="toc-section-number">14</span> Adventures in Covariance</a></li>
<li><a href="15-missing-data-and-other-opportunities.html#missing-data-and-other-opportunities"><span class="toc-section-number">15</span> Missing Data and Other Opportunities</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="multicollinearity" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Multicollinearity</h2>
<p>Means a very strong association between two or more predictors.</p>
<p>Consequence: the posterior distribution will seem to suggest that none of the variables is reliably associated with the outcome, even if all of the variables are in reality strongly associated with the outcome.</p>
<p>That said, the model will work fine for prediction; you will jsut be frustrated trying to understand it.</p>
<p><strong><em>6.1.1 Multicollinear legs</em></strong></p>
<p>Imagine trying to predict an individual’s height using the length of their legs as a predictor. But once you put both legs (right and left) into the model, something vexing will happen.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="6-1-multicollinearity.html#cb280-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># number of individuals</span></span>
<span id="cb280-2"><a href="6-1-multicollinearity.html#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">909</span>)</span>
<span id="cb280-3"><a href="6-1-multicollinearity.html#cb280-3" aria-hidden="true" tabindex="-1"></a>height <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">10</span>,<span class="dv">2</span>) <span class="co"># sim total height of each</span></span>
<span id="cb280-4"><a href="6-1-multicollinearity.html#cb280-4" aria-hidden="true" tabindex="-1"></a>leg_prop <span class="ot">&lt;-</span> <span class="fu">runif</span>(N,<span class="fl">0.4</span>,<span class="fl">0.5</span>) <span class="co"># leg as proportion of height</span></span>
<span id="cb280-5"><a href="6-1-multicollinearity.html#cb280-5" aria-hidden="true" tabindex="-1"></a>leg_left <span class="ot">&lt;-</span> leg_prop<span class="sc">*</span>height <span class="sc">+</span> <span class="co"># sim left leg as proportion + error</span></span>
<span id="cb280-6"><a href="6-1-multicollinearity.html#cb280-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>( N , <span class="dv">0</span> , <span class="fl">0.02</span> )</span>
<span id="cb280-7"><a href="6-1-multicollinearity.html#cb280-7" aria-hidden="true" tabindex="-1"></a>leg_right <span class="ot">&lt;-</span> leg_prop<span class="sc">*</span>height <span class="sc">+</span> <span class="co"># sim right leg as proportion + error</span></span>
<span id="cb280-8"><a href="6-1-multicollinearity.html#cb280-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>( N , <span class="dv">0</span> , <span class="fl">0.02</span> )</span>
<span id="cb280-9"><a href="6-1-multicollinearity.html#cb280-9" aria-hidden="true" tabindex="-1"></a><span class="co"># combine into data frame</span></span>
<span id="cb280-10"><a href="6-1-multicollinearity.html#cb280-10" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(height,leg_left,leg_right)</span></code></pre></div>
<p>We expect the beta coefficient that measures the association of a leg with height to end up around the average height (10) divided by 45% of the average height (4.5).</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="6-1-multicollinearity.html#cb281-1" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb281-2"><a href="6-1-multicollinearity.html#cb281-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb281-3"><a href="6-1-multicollinearity.html#cb281-3" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb281-4"><a href="6-1-multicollinearity.html#cb281-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bl<span class="sc">*</span>leg_left <span class="sc">+</span> br<span class="sc">*</span>leg_right ,</span>
<span id="cb281-5"><a href="6-1-multicollinearity.html#cb281-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">100</span> ) ,</span>
<span id="cb281-6"><a href="6-1-multicollinearity.html#cb281-6" aria-hidden="true" tabindex="-1"></a>    bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb281-7"><a href="6-1-multicollinearity.html#cb281-7" aria-hidden="true" tabindex="-1"></a>    br <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb281-8"><a href="6-1-multicollinearity.html#cb281-8" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb281-9"><a href="6-1-multicollinearity.html#cb281-9" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d )</span>
<span id="cb281-10"><a href="6-1-multicollinearity.html#cb281-10" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m6<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##            mean         sd       5.5%     94.5%
## a     0.9812791 0.28395540  0.5274635 1.4350947
## bl    0.2118585 2.52703706 -3.8268348 4.2505518
## br    1.7836774 2.53125061 -2.2617500 5.8291047
## sigma 0.6171026 0.04343427  0.5476862 0.6865189</code></pre>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="6-1-multicollinearity.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m6<span class="fl">.1</span>))</span></code></pre></div>
<p><img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/unnamed-chunk-12-1.svg" width="672" /></p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="6-1-multicollinearity.html#cb284-1" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m6<span class="fl">.1</span>)</span>
<span id="cb284-2"><a href="6-1-multicollinearity.html#cb284-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( bl <span class="sc">~</span> br , post , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) , <span class="at">pch=</span><span class="dv">16</span> )</span></code></pre></div>
<p><img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/6.5-1.svg" width="672" /></p>
<p>The posterior distribution for these two parameters is very hgihly correlated, with all of the plausible values of <code>bl</code> and <code>br</code> lying around a narrow ridge. When <code>bl</code> is large, then <code>br</code> must be small. Since both leg variables contain almost exactly the same information, if you insist on including both in a model, then there will be a practically infinite number of combinations of <code>bl</code> and <code>br</code> that produce the same predictions.</p>
<p>Compute the posterior distribution and plot it.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="6-1-multicollinearity.html#cb285-1" aria-hidden="true" tabindex="-1"></a>sum_blbr <span class="ot">&lt;-</span> post<span class="sc">$</span>bl <span class="sc">+</span> post<span class="sc">$</span>br</span>
<span id="cb285-2"><a href="6-1-multicollinearity.html#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( sum_blbr , <span class="at">col=</span>rangi2 , <span class="at">lwd=</span><span class="dv">2</span> , <span class="at">xlab=</span><span class="st">&quot;sum of bl and br&quot;</span> )</span></code></pre></div>
<p><img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/6.6-1.svg" width="672" /></p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="6-1-multicollinearity.html#cb286-1" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb286-2"><a href="6-1-multicollinearity.html#cb286-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb286-3"><a href="6-1-multicollinearity.html#cb286-3" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb286-4"><a href="6-1-multicollinearity.html#cb286-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bl<span class="sc">*</span>leg_left,</span>
<span id="cb286-5"><a href="6-1-multicollinearity.html#cb286-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">100</span> ) ,</span>
<span id="cb286-6"><a href="6-1-multicollinearity.html#cb286-6" aria-hidden="true" tabindex="-1"></a>    bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb286-7"><a href="6-1-multicollinearity.html#cb286-7" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb286-8"><a href="6-1-multicollinearity.html#cb286-8" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d )</span>
<span id="cb286-9"><a href="6-1-multicollinearity.html#cb286-9" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m6<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>##            mean         sd      5.5%    94.5%
## a     0.9979326 0.28364620 0.5446112 1.451254
## bl    1.9920676 0.06115704 1.8943269 2.089808
## sigma 0.6186038 0.04353998 0.5490185 0.688189</code></pre>
<p>The basic lesson is this:
&gt;When two predictor varilables are very strongly correlated (conditional on other variables int he model), including both in a model may lead to confusion.</p>
<p><strong><em>6.1.2. Multicollinear milk</em></strong></p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="6-1-multicollinearity.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb288-2"><a href="6-1-multicollinearity.html#cb288-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb288-3"><a href="6-1-multicollinearity.html#cb288-3" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb288-4"><a href="6-1-multicollinearity.html#cb288-4" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>K <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">standardize</span>( d<span class="sc">$</span>kcal.per.g )</span>
<span id="cb288-5"><a href="6-1-multicollinearity.html#cb288-5" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>F <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">standardize</span>( d<span class="sc">$</span>perc.fat )</span>
<span id="cb288-6"><a href="6-1-multicollinearity.html#cb288-6" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>L <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">standardize</span>( d<span class="sc">$</span>perc.lactose )</span></code></pre></div>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="6-1-multicollinearity.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="co"># kcal.per.g regressed on perc.fat</span></span>
<span id="cb289-2"><a href="6-1-multicollinearity.html#cb289-2" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb289-3"><a href="6-1-multicollinearity.html#cb289-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb289-4"><a href="6-1-multicollinearity.html#cb289-4" aria-hidden="true" tabindex="-1"></a>    K <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb289-5"><a href="6-1-multicollinearity.html#cb289-5" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bF<span class="sc">*</span>F ,</span>
<span id="cb289-6"><a href="6-1-multicollinearity.html#cb289-6" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.2</span> ) ,</span>
<span id="cb289-7"><a href="6-1-multicollinearity.html#cb289-7" aria-hidden="true" tabindex="-1"></a>    bF <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.5</span> ) ,</span>
<span id="cb289-8"><a href="6-1-multicollinearity.html#cb289-8" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb289-9"><a href="6-1-multicollinearity.html#cb289-9" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d )</span>
<span id="cb289-10"><a href="6-1-multicollinearity.html#cb289-10" aria-hidden="true" tabindex="-1"></a><span class="co"># kcal.per.g regressed on perc.lactose</span></span>
<span id="cb289-11"><a href="6-1-multicollinearity.html#cb289-11" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb289-12"><a href="6-1-multicollinearity.html#cb289-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb289-13"><a href="6-1-multicollinearity.html#cb289-13" aria-hidden="true" tabindex="-1"></a>    K <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb289-14"><a href="6-1-multicollinearity.html#cb289-14" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bL<span class="sc">*</span>L ,</span>
<span id="cb289-15"><a href="6-1-multicollinearity.html#cb289-15" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.2</span> ) ,</span>
<span id="cb289-16"><a href="6-1-multicollinearity.html#cb289-16" aria-hidden="true" tabindex="-1"></a>    bL <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.5</span> ) ,</span>
<span id="cb289-17"><a href="6-1-multicollinearity.html#cb289-17" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb289-18"><a href="6-1-multicollinearity.html#cb289-18" aria-hidden="true" tabindex="-1"></a>  ) , <span class="at">data=</span>d )</span>
<span id="cb289-19"><a href="6-1-multicollinearity.html#cb289-19" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m6<span class="fl">.3</span> )</span></code></pre></div>
<pre><code>##               mean         sd       5.5%     94.5%
## a     1.535526e-07 0.07725195 -0.1234634 0.1234637
## bF    8.618970e-01 0.08426088  0.7272318 0.9965621
## sigma 4.510179e-01 0.05870756  0.3571919 0.5448440</code></pre>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="6-1-multicollinearity.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m6<span class="fl">.4</span> )</span></code></pre></div>
<pre><code>##                mean         sd       5.5%      94.5%
## a      7.438895e-07 0.06661633 -0.1064650  0.1064665
## bL    -9.024550e-01 0.07132848 -1.0164517 -0.7884583
## sigma  3.804653e-01 0.04958259  0.3012227  0.4597078</code></pre>
<p>Given the strong association of each predictor with the outcome, we might conclude that both variables are reliable predictors of total energy in milk, across species. But watch what happens when we place both predictor variables in the same regression model:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="6-1-multicollinearity.html#cb293-1" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">quap</span>(</span>
<span id="cb293-2"><a href="6-1-multicollinearity.html#cb293-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb293-3"><a href="6-1-multicollinearity.html#cb293-3" aria-hidden="true" tabindex="-1"></a>    K <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb293-4"><a href="6-1-multicollinearity.html#cb293-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bF<span class="sc">*</span>F <span class="sc">+</span> bL<span class="sc">*</span>L ,</span>
<span id="cb293-5"><a href="6-1-multicollinearity.html#cb293-5" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.2</span> ) ,</span>
<span id="cb293-6"><a href="6-1-multicollinearity.html#cb293-6" aria-hidden="true" tabindex="-1"></a>    bF <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.5</span> ) ,</span>
<span id="cb293-7"><a href="6-1-multicollinearity.html#cb293-7" aria-hidden="true" tabindex="-1"></a>    bL <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="fl">0.5</span> ) ,</span>
<span id="cb293-8"><a href="6-1-multicollinearity.html#cb293-8" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb293-9"><a href="6-1-multicollinearity.html#cb293-9" aria-hidden="true" tabindex="-1"></a>  ) ,</span>
<span id="cb293-10"><a href="6-1-multicollinearity.html#cb293-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data=</span>d )</span>
<span id="cb293-11"><a href="6-1-multicollinearity.html#cb293-11" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m6<span class="fl">.5</span> )</span></code></pre></div>
<pre><code>##                mean         sd        5.5%      94.5%
## a     -3.172136e-07 0.06603577 -0.10553823  0.1055376
## bF     2.434983e-01 0.18357865 -0.04989579  0.5368925
## bL    -6.780825e-01 0.18377670 -0.97179320 -0.3843719
## sigma  3.767418e-01 0.04918394  0.29813637  0.4553472</code></pre>
<p>Now the posterior means of both bF and bL are closer to zero. And the standard deviations for both parameters are twice as large as in the bivariate models (m6.3 and m6.4).</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="6-1-multicollinearity.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>( <span class="sc">~</span> kcal.per.g <span class="sc">+</span> perc.fat <span class="sc">+</span> perc.lactose , <span class="at">data=</span>d , <span class="at">col=</span>rangi2 )</span></code></pre></div>
<p><img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/6.11-1.svg" width="672" /></p>
<p>Either helps in predicting kcal.per.g, but neither helps as much <em>once you already know the other</em>.</p>
<p>Some fields actually teach students to inspect pairwise correlations before fitting a model, to identify and drop highly correlated predictors. This is a mistake. Pairwise correlations are not the problem. It is the conditional associations—not correlations—that matter.</p>
<p>Now let’s see how the imprecision of the posterior increases with association between two predictors.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="6-1-multicollinearity.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb296-2"><a href="6-1-multicollinearity.html#cb296-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb296-3"><a href="6-1-multicollinearity.html#cb296-3" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb296-4"><a href="6-1-multicollinearity.html#cb296-4" aria-hidden="true" tabindex="-1"></a>sim.coll <span class="ot">&lt;-</span> <span class="cf">function</span>( <span class="at">r=</span><span class="fl">0.9</span> ) {</span>
<span id="cb296-5"><a href="6-1-multicollinearity.html#cb296-5" aria-hidden="true" tabindex="-1"></a>  d<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( <span class="fu">nrow</span>(d) , <span class="at">mean=</span>r<span class="sc">*</span>d<span class="sc">$</span>perc.fat ,</span>
<span id="cb296-6"><a href="6-1-multicollinearity.html#cb296-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd=</span><span class="fu">sqrt</span>( (<span class="dv">1</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">var</span>(d<span class="sc">$</span>perc.fat) ) )</span>
<span id="cb296-7"><a href="6-1-multicollinearity.html#cb296-7" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">lm</span>( kcal.per.g <span class="sc">~</span> perc.fat <span class="sc">+</span> x , <span class="at">data=</span>d )</span>
<span id="cb296-8"><a href="6-1-multicollinearity.html#cb296-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>( <span class="fu">diag</span>( <span class="fu">vcov</span>(m) ) )[<span class="dv">2</span>] <span class="co"># stddev of parameter</span></span>
<span id="cb296-9"><a href="6-1-multicollinearity.html#cb296-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb296-10"><a href="6-1-multicollinearity.html#cb296-10" aria-hidden="true" tabindex="-1"></a>rep.sim.coll <span class="ot">&lt;-</span> <span class="cf">function</span>( <span class="at">r=</span><span class="fl">0.9</span> , <span class="at">n=</span><span class="dv">100</span> ) {</span>
<span id="cb296-11"><a href="6-1-multicollinearity.html#cb296-11" aria-hidden="true" tabindex="-1"></a>  stddev <span class="ot">&lt;-</span> <span class="fu">replicate</span>( n , <span class="fu">sim.coll</span>(r) )</span>
<span id="cb296-12"><a href="6-1-multicollinearity.html#cb296-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(stddev)</span>
<span id="cb296-13"><a href="6-1-multicollinearity.html#cb296-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb296-14"><a href="6-1-multicollinearity.html#cb296-14" aria-hidden="true" tabindex="-1"></a>r.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="fl">0.99</span>,<span class="at">by=</span><span class="fl">0.01</span>)</span>
<span id="cb296-15"><a href="6-1-multicollinearity.html#cb296-15" aria-hidden="true" tabindex="-1"></a>stddev <span class="ot">&lt;-</span> <span class="fu">sapply</span>( r.seq , <span class="cf">function</span>(z) <span class="fu">rep.sim.coll</span>(<span class="at">r=</span>z,<span class="at">n=</span><span class="dv">100</span>) )</span>
<span id="cb296-16"><a href="6-1-multicollinearity.html#cb296-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( stddev <span class="sc">~</span> r.seq , <span class="at">type=</span><span class="st">&quot;l&quot;</span> , <span class="at">col=</span>rangi2, <span class="at">lwd=</span><span class="dv">2</span> , <span class="at">xlab=</span><span class="st">&quot;correlation&quot;</span> )</span></code></pre></div>
<p><img src="06_the_haunted_dag_and_the_causal_terror_files/figure-html/6.12-1.svg" width="672" /></p>
</div>
<p style="text-align: center;">
<a href="6-the-haunted-dag-the-causal-terror.html"><button class="btn btn-default">Previous</button></a>
<a href="6-2-post-treatment-bias.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
