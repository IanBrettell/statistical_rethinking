<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 6. The Haunted DAG &amp; The Causal Terror" />
<meta property="og:type" content="book" />






<meta name="date" content="2021-05-12" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 6. The Haunted DAG &amp; The Causal Terror">

<title>Chapter 6. The Haunted DAG &amp; The Causal Terror</title>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="#the-haunted-dag-the-causal-terror"><span class="toc-section-number">1</span> The Haunted DAG &amp; The Causal Terror</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="header">
<h1 class="title">Chapter 6. The Haunted DAG &amp; The Causal Terror</h1>
<h4 class="date"><em>2021-05-12</em></h4>
</div>
<div id="the-haunted-dag-the-causal-terror" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> The Haunted DAG &amp; The Causal Terror</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(here)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;code/scripts/source.R&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>slides_dir <span class="ot">=</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;docs/slides/L06&quot;</span>)</span></code></pre></div>
<p><img src="slides/L06/01.png" width="80%"  /></p>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<p class="caption marginnote shownote">
Figure 1.1: Interesting feature of scientific literature is that there’s a negative correlation between surprising things and true things. The most trustworthy science is incredibly boring. Paper from PNAS. Hurricanes get names. They had this convention of alternating names. You can regress them, and if you do a terrible regression, female hurricanes are deadlier, but it’s not robust. And there’s no robust mechanism.
</p>
<img src="slides/L06/05.png" alt="Interesting feature of scientific literature is that there's a negative correlation between surprising things and true things. The most trustworthy science is incredibly boring. Paper from PNAS. Hurricanes get names. They had this convention of alternating names. You can regress them, and if you do a terrible regression, female hurricanes are deadlier, but it's not robust. And there's no robust mechanism." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<p class="caption marginnote shownote">
Figure 1.2: This is Mono Lake, with high levels of arsenic. Why’s that bad? Arsenate mimics phosphate, and things break. How do the organisms in this lake adapt to it? Dr Wolfe-Simon published a study showing evidence that bacteria in the lake were using arsenic in their DNA. Since then it turns out it probably wasn’t true, even though it was a rigorous study.
</p>
<img src="slides/L06/06.png" alt="This is Mono Lake, with high levels of arsenic. Why's that bad? Arsenate mimics phosphate, and things break. How do the organisms in this lake adapt to it? Dr Wolfe-Simon published a study showing evidence that bacteria in the lake were using arsenic in their DNA. Since then it turns out it probably wasn't true, even though it was a rigorous study." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<p class="caption marginnote shownote">
Figure 1.3: We don’t need any elaborate theory that we all have. All you need to get a negative correlation between newsworthy things and trustworthy things are peer-review. Here’s a simulated example. Imagine that either journals or grant-review panels, you care about both. But you also care about rigour. A study can get published or funding <em>if</em> it’s sufficiently trustworthy <em>or</em> it’s sufficiently newsworthy. So even it there’s no correlation in the production of science, post-selection there’ll be a negative correlation. Here you can see there’s no correlation. There’s a threshold of the sum of newsworthiness and trustowrthiness. The blue are the ones that get funded, and the correlations are -0.8. You can’t know from the correlation what’s happening generatively. This is a spurious correlation. Conditioning on a variable in a regression is a selection process. Don’t just add things to regressions. It’s called a Simpson’s paradox.
</p>
<img src="slides/L06/07.png" alt="We don't need any elaborate theory that we all have. All you need to get a negative correlation between newsworthy things and trustworthy things are peer-review. Here's a simulated example. Imagine that either journals or grant-review panels, you care about both. But you also care about rigour. A study can get published or funding *if* it's sufficiently trustworthy *or* it's sufficiently newsworthy. So even it there's no correlation in the production of science, post-selection there'll be a negative correlation. Here you can see there's no correlation. There's a threshold of the sum of newsworthiness and trustowrthiness. The blue are the ones that get funded, and the correlations are -0.8. You can't know from the correlation what's happening generatively. This is a spurious correlation. Conditioning on a variable in a regression is a selection process. Don't just add things to regressions. It's called a Simpson's paradox." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-7"></span>
<p class="caption marginnote shownote">
Figure 1.4: Regression is an incredible tool. But it’s an oracle. It automatically finds the most informative cases. It’s amazing that the universe is designed such that this works out. But it’s a historical oracle. Like the Oracle of Delphi. Poweful, but not benign. Or like a genie. Will take your wish (question) very literally.
</p>
<img src="slides/L06/08.png" alt="Regression is an incredible tool. But it's an oracle. It automatically finds the most informative cases. It's amazing that the universe is designed such that this works out. But it's a historical oracle. Like the Oracle of Delphi. Poweful, but not benign. Or like a genie. Will take your wish (question) very literally." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<p class="caption marginnote shownote">
Figure 1.5: “Table 2”: uninterpretable causal salad. Adding variable can create confounds.
</p>
<img src="slides/L06/09.png" alt="&quot;Table 2&quot;: uninterpretable causal salad. Adding variable can create confounds." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<p class="caption marginnote shownote">
Figure 1.6: Going to use a lot of simulated examples. Actually there’s this benign fact that there are only four confounds. Ignoring those things, these are the only kinds we get. Going to explain each of them to see what they do. Going to learn how to de-confound each of them. If you know the causal graph, you can deconfound or conclude that it’s hopeless and can’t confound. So we’ll come back to this.
</p>
<img src="slides/L06/10.png" alt="Going to use a lot of simulated examples. Actually there's this benign fact that there are only four confounds. Ignoring those things, these are the only kinds we get. Going to explain each of them to see what they do. Going to learn how to de-confound each of them. If you know the causal graph, you can deconfound or conclude that it's hopeless and can't confound. So we'll come back to this." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<p class="caption marginnote shownote">
Figure 1.7: The most famous confound. Variable that is a common cause of two others. Median age of marriage creates a fork. Creates a spurious correlation between M and D. Interested in the causal effect of X on Y. In the fork, you deconfound by conditioning on Z and shut the fork. There’s this notation at the bottom of the slide. X is independent on Y conditional on Z.
</p>
<img src="slides/L06/11.png" alt="The most famous confound. Variable that is a common cause of two others. Median age of marriage creates a fork. Creates a spurious correlation between M and D. Interested in the causal effect of X on Y. In the fork, you deconfound by conditioning on Z and shut the fork. There's this notation at the bottom of the slide. X is independent on Y conditional on Z." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<p class="caption marginnote shownote">
Figure 1.8: The pipe is a lot like the fork. Here there’s a mediation. In reality X is mediated by Z. If we condition on Z, we don’t notice the true effect. If you condition on Z, then you remove the dependency between X and Y. From the data alone, you can’t see the difference between a pipe and a fork.
</p>
<img src="slides/L06/12.png" alt="The pipe is a lot like the fork. Here there's a mediation. In reality X is mediated by Z. If we condition on Z, we don't notice the true effect. If you condition on Z, then you remove the dependency between X and Y. From the data alone, you can't see the difference between a pipe and a fork. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-12"></span>
<p class="caption marginnote shownote">
Figure 1.9: The confound that gets created is the “post-treatment bias”, Z. Post-treatment variables arise as a consequence of treatment. This happens a lot. The bias occurs when you’re not aware of Z, and end up inferring something wrong.
</p>
<img src="slides/L06/13.png" alt="The confound that gets created is the &quot;post-treatment bias&quot;, Z. Post-treatment variables arise as a consequence of treatment. This happens a lot. The bias occurs when you're not aware of Z, and end up inferring something wrong. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<p class="caption marginnote shownote">
Figure 1.10: Let’s imagine an experiment where there’s fungal growth in a greenhouse, and you have an anti-fungal treatment, and you randomly assign plants to either the treatment or control. The initial height of the plant is H0. The anti-fungal treatment is upstream from the fungus, but doesn’t influence it directly. What happens here in a regression is if you measure fungus - which is how you test for mediation - but what you’re interested in is the full path from T to H1. If you condition on F, it’ll look like the treatment doesn’t work. If you condition on F, you block the pipe, and information doesn’t flow from T to H1. In observational studies, the terror is real.
</p>
<img src="slides/L06/14.png" alt="Let's imagine an experiment where there's fungal growth in a greenhouse, and you have an anti-fungal treatment, and you randomly assign plants to either the treatment or control. The initial height of the plant is H0. The anti-fungal treatment is upstream from the fungus, but doesn't influence it directly. What happens here in a regression is if you measure fungus - which is how you test for mediation - but what you're interested in is the full path from T to H1. If you condition on F, it'll look like the treatment doesn't work. If you condition on F, you block the pipe, and information doesn't flow from T to H1. In observational studies, the terror is real. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-14"></span>
<p class="caption marginnote shownote">
Figure 1.11: Frustrating thing for statisticians is that if you condition on career choice, there’s basically no wage gap. But that doesn’t mean gender and race isn’t causal, because there are streams where something downstream knocks it out. If you look at funding rates for the sciences, women get way less grant money. But not if you condition on field.
</p>
<img src="slides/L06/15.png" alt="Frustrating thing for statisticians is that if you condition on career choice, there's basically no wage gap. But that doesn't mean gender and race isn't causal, because there are streams where something downstream knocks it out. If you look at funding rates for the sciences, women get way less grant money. But not if you condition on field. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-15"></span>
<p class="caption marginnote shownote">
Figure 1.12: This is where the selection effect comes from. Like the fork but in reverse. Here <code>Z</code> is a common result of <code>X</code> and <code>Y</code>. X and Y are really independent, but if you condition on Z, it creates a spurious causal connection between X and Y. There’s this “finding out” effect.
</p>
<img src="slides/L06/16.png" alt="This is where the selection effect comes from. Like the fork but in reverse. Here `Z` is a common result of `X` and `Y`. X and Y are really independent, but if you condition on Z, it creates a spurious causal connection between X and Y. There's this &quot;finding out&quot; effect. " width="80%"  />
</div>
<p><img src="slides/L06/17.png" width="80%"  /></p>
<div class="figure"><span id="fig:unnamed-chunk-17"></span>
<p class="caption marginnote shownote">
Figure 1.13: This is the finding out effect. Works for continuous variables as well.
</p>
<img src="slides/L06/18.png" alt="This is the finding out effect. Works for continuous variables as well. " width="80%"  />
</div>
<p><img src="slides/L06/19.png" width="80%"  /></p>
<div class="figure"><span id="fig:unnamed-chunk-19"></span>
<p class="caption marginnote shownote">
Figure 1.14: Both influence publication.
</p>
<img src="slides/L06/20.png" alt="Both influence publication." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<p class="caption marginnote shownote">
Figure 1.15: So if it’s been published in Nature and isn’t trustworthy, can you tell me how newsworthy it is?
</p>
<img src="slides/L06/21.png" alt="So if it's been published in Nature and isn't trustworthy, can you tell me how newsworthy it is?" width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-21"></span>
<p class="caption marginnote shownote">
Figure 1.16: There are lots of effects like this that happen all the time. Being tall is definitely causatively-speaking an advantage. The taller you are, the easier to score field goals. But conditional on being a professional player, there’s no correlation between height and shooting percentage. Because the shorter players are compensating by being amazing in other ways. They’ve been distorted by the selection effects.
</p>
<img src="slides/L06/22.png" alt="There are lots of effects like this that happen all the time. Being tall is definitely causatively-speaking an advantage. The taller you are, the easier to score field goals. But conditional on being a professional player, there's no correlation between height and shooting percentage. Because the shorter players are compensating by being amazing in other ways. They've been distorted by the selection effects." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-22"></span>
<p class="caption marginnote shownote">
Figure 1.17: Let’s do an example. Image this causal graph at the bottom. Imagine it’s true that getting married is positively, causally associated with happiness, and age. Now our question is, is there any causal impact of age on happiness? Here’s a simulation where it’s totally spurious.
</p>
<img src="slides/L06/23.png" alt="Let's do an example. Image this causal graph at the bottom. Imagine it's true that getting married is positively, causally associated with happiness, and age. Now our question is, is there any causal impact of age on happiness? Here's a simulation where it's totally spurious. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<p class="caption marginnote shownote">
Figure 1.18: Here the simulation is slightly different to the usual <code>rnorm</code>. Here’s the algorithm. Uniform happiness at birth. Distributed from 0 to 1. Reality is more complicated, even harder to figure out. At 18 years old, you’re eligible to marry. Then you have your coin-flip chance to get married. The chance is proportional to your happiness, which is constant. Age itself doesn’t cause marriage, but each year you’re alive you have another chance to get married. Married people remain married unto death. Then everyone moves to Spain. 1300 people, 3 variables, over 1000 years.
</p>
<img src="slides/L06/24.png" alt="Here the simulation is slightly different to the usual `rnorm`. Here's the algorithm. Uniform happiness at birth. Distributed from 0 to 1. Reality is more complicated, even harder to figure out. At 18 years old, you're eligible to marry. Then you have your coin-flip chance to get married. The chance is proportional to your happiness, which is constant. Age itself doesn't cause marriage, but each year you're alive you have another chance to get married. Married people remain married unto death. Then everyone moves to Spain. 1300 people, 3 variables, over 1000 years." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-24"></span>
<p class="caption marginnote shownote">
Figure 1.19: Here’s the system. Run a regression where we take happiness. Happiness is the outcome, then the linear model <code>mu</code>, the slope <code>a</code> which is age. That’s the exposure we’re interested in. And we know the marriage status, so perhaps we control for that. (No, that’s the wrong thing to do, as we’ll see.) Created an index variable. Then put that in as a control. We see that single people are less happy. Regression models don’t have arrows. It’s not in the Bayesian network; that’s what the DAG does. <code>a[2]</code> is married individuals. Positive <code>mu</code>. The slope is solidly negative. But this is a spurious correlation by conditioning on a collider.
</p>
<img src="slides/L06/25.png" alt="Here's the system. Run a regression where we take happiness. Happiness is the outcome, then the linear model `mu`, the slope `a` which is age. That's the exposure we're interested in. And we know the marriage status, so perhaps we control for that. (No, that's the wrong thing to do, as we'll see.) Created an index variable. Then put that in as a control. We see that single people are less happy. Regression models don't have arrows. It's not in the Bayesian network; that's what the DAG does. `a[2]` is married individuals. Positive `mu`. The slope is solidly negative. But this is a spurious correlation by conditioning on a collider. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-25"></span>
<p class="caption marginnote shownote">
Figure 1.20: We know that happiness doesn’t change and doesn’t decline with age, because that’s how we coded it. But if we stratify by marriage status, it does. Each point is a person. Each year 20 individuals are born. Happiness is uniformly distributed and constant. Blue filled are married. Starting early on the blue points are only at the top. But over time, indiviuals who are less happy will also get married. By 65, most of the population in the simulation is married.
</p>
<img src="slides/L06/26.png" alt="We know that happiness doesn't change and doesn't decline with age, because that's how we coded it. But if we stratify by marriage status, it does. Each point is a person. Each year 20 individuals are born. Happiness is uniformly distributed and constant. Blue filled are married. Starting early on the blue points are only at the top. But over time, indiviuals who are less happy will also get married. By 65, most of the population in the simulation is married." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-26"></span>
<p class="caption marginnote shownote">
Figure 1.21: Now if we draw regression lines, we can see there’s a negative correlation. But the distribution of happiness has not changed for anybody.
</p>
<img src="slides/L06/27.png" alt="Now if we draw regression lines, we can see there's a negative correlation. But the distribution of happiness has not changed for anybody." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-27"></span>
<p class="caption marginnote shownote">
Figure 1.22: If we condition on it, we allow information to flow from age to happiness. In reality we don’t know, so we need to use information external to the data.
</p>
<img src="slides/L06/28.png" alt="If we condition on it, we allow information to flow from age to happiness. In reality we don't know, so we need to use information external to the data. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-28"></span>
<p class="caption marginnote shownote">
Figure 1.23: Another example. Colliders are so powerful they can even occur when you haven’t measured the confounder. In my subfield, we’re interested in allopaternal effects. What is the material benefit of having grandparents? There are resource and information flows, so we want to figure out how important they are. How do you figure this out empirically? Say you have triads, and you’re looking at educational outcomes. Indirect path through P, say through books. But also a potential direct effects during say babysitting. But regressions can show that grandparents have a negative effect?
</p>
<img src="slides/L06/29.png" alt="Another example. Colliders are so powerful they can even occur when you haven't measured the confounder. In my subfield, we're interested in allopaternal effects. What is the material benefit of having grandparents? There are resource and information flows, so we want to figure out how important they are. How do you figure this out empirically? Say you have triads, and you're looking at educational outcomes. Indirect path through P, say through books. But also a potential direct effects during say babysitting. But regressions can show that grandparents have a negative effect?" width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-29"></span>
<p class="caption marginnote shownote">
Figure 1.24: It’s plausible that parents and children share unobserved confounds. Whenever you do observational studies, there are <code>U</code>s all over the place. e.g. the neighbourhood you live in. School and neighbourhood effects are really powerful. Makes parents into a collider. So if we condition on parents, it becomes a collider.
</p>
<img src="slides/L06/30.png" alt="It's plausible that parents and children share unobserved confounds. Whenever you do observational studies, there are `U`s all over the place. e.g. the neighbourhood you live in. School and neighbourhood effects are really powerful. Makes parents into a collider. So if we condition on parents, it becomes a collider. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-30"></span>
<p class="caption marginnote shownote">
Figure 1.25: So we simulate this. Assuming that the direct path is 0.
</p>
<img src="slides/L06/31.png" alt="So we simulate this. Assuming that the direct path is 0." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-31"></span>
<p class="caption marginnote shownote">
Figure 1.26: We end up concluding that grandparents hurt their kids. How does this work? Conditioning on a collider opens a path. It’s closed by default. This oepns a path from G through U to see, which creates a spurious correlation.
</p>
<img src="slides/L06/32.png" alt="We end up concluding that grandparents hurt their kids. How does this work? Conditioning on a collider opens a path. It's closed by default. This oepns a path from G through U to see, which creates a spurious correlation." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-32"></span>
<p class="caption marginnote shownote">
Figure 1.27: One way to think about this is on the left we have good neighbourhoods in blue. All filled in points are where the parents are in a particular stratum. Why is it negative? Focus only on parents in the narrow range of educational outcomes. Parents in the good neighbourhoods, to be within this range, they must have had less educated grandparents. There are two ways to become a highly-educated parent. Either you are in a good neighbourhood, or you had an educated parent yourself. Each end the P box.
</p>
<img src="slides/L06/33.png" alt="One way to think about this is on the left we have good neighbourhoods in blue. All filled in points are where the parents are in a particular stratum. Why is it negative? Focus only on parents in the narrow range of educational outcomes. Parents in the good neighbourhoods, to be within this range, they must have had less educated grandparents. There are two ways to become a highly-educated parent. Either you are in a good neighbourhood, or you had an educated parent yourself. Each end the P box. " width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-33"></span>
<p class="caption marginnote shownote">
Figure 1.28: The back door criterion is that you want to figure out the true causal impact on some outcome, you need to shut all backdoor paths from the treatment to the outcome. We have to shut that arrow off to infer a true causal effect. In experiments you shut all the backdoor paths by randomising. But in observational studies, you want some set of criteria for what variables you should include to shut the paths.
</p>
<img src="slides/L06/34.png" alt="The back door criterion is that you want to figure out the true causal impact on some outcome, you need to shut all backdoor paths from the treatment to the outcome. We have to shut that arrow off to infer a true causal effect. In experiments you shut all the backdoor paths by randomising. But in observational studies, you want some set of criteria for what variables you should include to shut the paths." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-34"></span>
<p class="caption marginnote shownote">
Figure 1.29: These are the only ways that variables interact in these graphs.
</p>
<img src="slides/L06/35.png" alt="These are the only ways that variables interact in these graphs. " width="80%"  />
</div>
<p><img src="slides/L06/36.png" width="80%"  /></p>
<p><img src="slides/L06/37.png" width="80%"  /></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>slides_dir <span class="ot">=</span> here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;docs/slides/L07&quot;</span>)</span></code></pre></div>
<p><img src="slides/L07/01.png" width="80%"  /></p>
<div class="figure"><span id="fig:unnamed-chunk-39"></span>
<p class="caption marginnote shownote">
Figure 1.30: You can solve causal inference by assuming the DAG is true. There is a framework that unites all these examples: the <strong>back-door criterion</strong>. We need to shut all the back door paths into the exposure. There are only really three different ways they can meet in the DAG.
</p>
<img src="slides/L07/02.png" alt="You can solve causal inference by assuming the DAG is true. There is a framework that unites all these examples: the **back-door criterion**. We need to shut all the back door paths into the exposure. There are only really three different ways they can meet in the DAG." width="80%"  />
</div>
<div class="figure"><span id="fig:unnamed-chunk-40"></span>
<p class="caption marginnote shownote">
Figure 1.31: Break the fork by conditioning on Z. Block the pipe by conditioning on Z. The collider only opens the path if you condition on it. Conditioning on a descendant of a collider is like conditioning on a collider, depending on how strong the relationship is.
</p>
<img src="slides/L07/03.png" alt="Break the fork by conditioning on Z. Block the pipe by conditioning on Z. The collider only opens the path if you condition on it. Conditioning on a descendant of a collider is like conditioning on a collider, depending on how strong the relationship is. " width="80%"  />
</div>
<p><img src="slides/L07/04.png" width="80%"  /></p>
<p><label for="tufte-mn-1" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-1" class="margin-toggle"><span class="marginnote"><span style="display: block;">The classic confound involves some exposure <span class="math inline"><span class="math inline">\(E\)</span></span>. A lot of research goes into understanding what the returns on education are. There are a lot of confounds <span class="math inline"><span class="math inline">\(U\)</span></span>. How do we de-confound this DAG using the back-door criterion? <span class="math inline"><span class="math inline">\(E \leftarrow U \rightarrow W\)</span></span>. How to shut this? It’s a fork, and you close it by conditioning on <span class="math inline"><span class="math inline">\(U\)</span></span>. But here it’s unobserved, so we can’t condition on it. You therefore can’t get an unbiased estimate. But that’s an achievement, because we’ve wasted less time.</span></span></p>
<div class="figure"><span id="fig:unnamed-chunk-43"></span>
<p class="caption marginnote shownote">
Figure 1.32: If we want to estimate the direct causal influence from grandparents to kids, we see there are three paths from G to C. If we condition on <span class="math inline">\(P\)</span>, that closes the second path through parents. Since that’s a pipe, you condition on parents, but that opens the other path, because they’re a collider between grandparents and unobserved neighbourhood effects. So we can’t get a valid estimate unless we measure it. This is happy news, because we know we’re being fooled.
</p>
<img src="slides/L07/05.png" alt="If we want to estimate the direct causal influence from grandparents to kids, we see there are three paths from G to C. If we condition on $P$, that closes the second path through parents. Since that's a pipe, you condition on parents, but that opens the other path, because they're a collider between grandparents and unobserved neighbourhood effects. So we can't get a valid estimate unless we measure it. This is happy news, because we know we're being fooled." width="80%"  />
</div>
<p><img src="slides/L07/06.png" width="80%"  /></p>
<p><img src="slides/L07/07.png" width="80%"  /></p>
<p><img src="slides/L07/08.png" width="80%"  /></p>
<p><img src="slides/L07/09.png" width="80%"  /></p>
<p><img src="slides/L07/10.png" width="80%"  /></p>
<p><img src="slides/L07/11.png" width="80%"  /></p>
<p><img src="slides/L07/12.png" width="80%"  /></p>
<p><img src="slides/L07/13.png" width="80%"  /></p>
<p><img src="slides/L07/14.png" width="80%"  /></p>
<p><img src="slides/L07/15.png" width="80%"  /></p>
<p><img src="slides/L07/16.png" width="80%"  /></p>
<p><img src="slides/L07/17.png" width="80%"  /></p>
<p><img src="slides/L07/18.png" width="80%"  /></p>
<p><img src="slides/L07/19.png" width="80%"  /></p>
<p><img src="slides/L07/20.png" width="80%"  /></p>
<p><img src="slides/L07/21.png" width="80%"  /></p>
<p><img src="slides/L07/22.png" width="80%"  /></p>
<p><img src="slides/L07/23.png" width="80%"  /></p>
<p><img src="slides/L07/24.png" width="80%"  /></p>
<p><img src="slides/L07/25.png" width="80%"  /></p>
<p><img src="slides/L07/26.png" width="80%"  /></p>
<p><img src="slides/L07/27.png" width="80%"  /></p>
<p><img src="slides/L07/28.png" width="80%"  /></p>
<p><img src="slides/L07/29.png" width="80%"  /></p>
<p><img src="slides/L07/30.png" width="80%"  /></p>
<p><img src="slides/L07/31.png" width="80%"  /></p>
<p><img src="slides/L07/32.png" width="80%"  /></p>
<p><img src="slides/L07/33.png" width="80%"  /></p>
<p><img src="slides/L07/34.png" width="80%"  /></p>
<p><img src="slides/L07/35.png" width="80%"  /></p>
<p><img src="slides/L07/36.png" width="80%"  /></p>
<p><img src="slides/L07/37.png" width="80%"  /></p>
<p><img src="slides/L07/38.png" width="80%"  /></p>
<p><img src="slides/L07/39.png" width="80%"  /></p>
<p><img src="slides/L07/40.png" width="80%"  /></p>
<p><img src="slides/L07/41.png" width="80%"  /></p>
<p><img src="slides/L07/42.png" width="80%"  /></p>
<p><img src="slides/L07/43.png" width="80%"  /></p>
</div>
<p style="text-align: center;">
</p>
</div>
</div>



</body>
</html>
